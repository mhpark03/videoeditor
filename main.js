// Load environment variables from .env file
require('dotenv').config();

const { app, BrowserWindow, ipcMain, dialog, Menu, shell } = require('electron');
const path = require('path');
const fs = require('fs');
const os = require('os');
const { spawn } = require('child_process');
const veoHelper = require('./veo-helper');
const imagenHelper = require('./imagen-helper');

let mainWindow;
let ffmpegPath;
let ffprobePath;

// Logging system
const LOGS_DIR = path.join(__dirname, 'logs');
let currentLogFilePath = null;
let currentLogDate = null;

// Ensure logs directory exists
function ensureLogsDirectory() {
  if (!fs.existsSync(LOGS_DIR)) {
    fs.mkdirSync(LOGS_DIR, { recursive: true });
  }
}

// Get Korea Standard Time formatted string
function toKST(date) {
  const kstDate = new Date(date.toLocaleString('en-US', { timeZone: 'Asia/Seoul' }));
  const year = kstDate.getFullYear();
  const month = String(kstDate.getMonth() + 1).padStart(2, '0');
  const day = String(kstDate.getDate()).padStart(2, '0');
  const hours = String(kstDate.getHours()).padStart(2, '0');
  const minutes = String(kstDate.getMinutes()).padStart(2, '0');
  const seconds = String(kstDate.getSeconds()).padStart(2, '0');
  return `${year}/${month}/${day}-${hours}:${minutes}:${seconds}`;
}

// Get log file path for current date
function getLogFilePath() {
  const date = new Date();
  const kstDate = new Date(date.toLocaleString('en-US', { timeZone: 'Asia/Seoul' }));
  const year = kstDate.getFullYear();
  const month = String(kstDate.getMonth() + 1).padStart(2, '0');
  const day = String(kstDate.getDate()).padStart(2, '0');
  const dateStr = `${year}-${month}-${day}`;

  if (currentLogFilePath && currentLogDate === dateStr) {
    return currentLogFilePath;
  }

  ensureLogsDirectory();

  let sequence = 1;
  let logPath;

  while (true) {
    const seqStr = String(sequence).padStart(3, '0');
    logPath = path.join(LOGS_DIR, `video-editor-${dateStr}-${seqStr}.log`);

    if (!fs.existsSync(logPath)) {
      break;
    }
    sequence++;

    if (sequence > 999) {
      const timestamp = toKST(new Date()).replace(/[/:]/g, '-');
      logPath = path.join(LOGS_DIR, `video-editor-${dateStr}-${timestamp}.log`);
      break;
    }
  }

  currentLogFilePath = logPath;
  currentLogDate = dateStr;
  console.log(`Log file: ${path.basename(logPath)}`);

  return logPath;
}

// Write log entry
function writeLog(level, eventType, message, data = null) {
  const timestamp = toKST(new Date());
  let logEntry = `[${timestamp}] [${level}] [${eventType}] ${message}`;

  if (data) {
    logEntry += ` | Data: ${JSON.stringify(data)}`;
  }

  logEntry += '\n';

  console.log(logEntry.trim());

  const logPath = getLogFilePath();
  try {
    // Write with UTF-8 BOM to ensure proper encoding
    const BOM = '\uFEFF';
    const existingContent = fs.existsSync(logPath) ? fs.readFileSync(logPath, 'utf8') : '';

    // Only add BOM if file is new or empty
    if (existingContent.length === 0) {
      fs.writeFileSync(logPath, BOM + logEntry, 'utf8');
    } else {
      fs.appendFileSync(logPath, logEntry, 'utf8');
    }
  } catch (error) {
    console.error('Error writing log:', error);
  }

  // Send to renderer
  if (mainWindow && mainWindow.webContents) {
    mainWindow.webContents.send('log-entry', {
      timestamp,
      level,
      eventType,
      message,
      data
    });
  }
}

// Log level helpers
function logInfo(eventType, message, data = null) {
  writeLog('INFO', eventType, message, data);
}

function logWarn(eventType, message, data = null) {
  writeLog('WARN', eventType, message, data);
}

function logError(eventType, message, data = null) {
  writeLog('ERROR', eventType, message, data);
}

// Create application menu
function createMenu() {
  const template = [
    {
      label: '파일',
      submenu: [
        {
          label: '로그 폴더 열기',
          click: () => {
            ensureLogsDirectory();
            shell.openPath(LOGS_DIR);
          }
        },
        { type: 'separator' },
        {
          label: '종료',
          accelerator: 'Alt+F4',
          click: () => {
            app.quit();
          }
        }
      ]
    },
    {
      label: '편집',
      submenu: [
        {
          label: '영상 편집 모드',
          accelerator: 'Ctrl+1',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('switch-mode', 'video');
            }
          }
        },
        {
          label: '음성 편집 모드',
          accelerator: 'Ctrl+2',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.send('switch-mode', 'audio');
            }
          }
        }
      ]
    },
    {
      label: '보기',
      submenu: [
        {
          label: '개발자 도구',
          accelerator: 'F12',
          click: () => {
            if (mainWindow) {
              mainWindow.webContents.toggleDevTools();
            }
          }
        },
        { type: 'separator' },
        {
          label: '새로고침',
          accelerator: 'F5',
          click: () => {
            if (mainWindow) {
              mainWindow.reload();
            }
          }
        }
      ]
    },
    {
      label: '도움말',
      submenu: [
        {
          label: '정보',
          click: () => {
            dialog.showMessageBox(mainWindow, {
              type: 'info',
              title: 'Kiosk Video Editor',
              message: 'Kiosk Video Editor v1.0.0',
              detail: '키오스크 관리 시스템을 위한 고급 영상/음성 편집 도구입니다.'
            });
          }
        }
      ]
    }
  ];

  const menu = Menu.buildFromTemplate(template);
  Menu.setApplicationMenu(menu);
}

// Find FFmpeg executable
function findFFmpegPath() {
  // Check if bundled FFmpeg exists
  const bundledPath = path.join(process.resourcesPath, 'ffmpeg', 'ffmpeg.exe');
  if (fs.existsSync(bundledPath)) {
    return bundledPath;
  }

  // Check local development path
  const devPath = path.join(__dirname, 'ffmpeg', 'ffmpeg.exe');
  if (fs.existsSync(devPath)) {
    return devPath;
  }

  // Fall back to system PATH
  return 'ffmpeg';
}

// Find FFprobe executable
function findFFprobePath() {
  // Check if bundled FFprobe exists
  const bundledPath = path.join(process.resourcesPath, 'ffmpeg', 'ffprobe.exe');
  if (fs.existsSync(bundledPath)) {
    return bundledPath;
  }

  // Check local development path
  const devPath = path.join(__dirname, 'ffmpeg', 'ffprobe.exe');
  if (fs.existsSync(devPath)) {
    return devPath;
  }

  // Fall back to system PATH
  return 'ffprobe';
}

function createWindow() {
  mainWindow = new BrowserWindow({
    width: 1600,
    height: 1000,
    webPreferences: {
      preload: path.join(__dirname, 'preload.js'),
      contextIsolation: true,
      nodeIntegration: false
    },
    icon: path.join(__dirname, 'assets', 'icon.png')
  });

  mainWindow.loadFile('renderer/index.html');

  // Create application menu
  createMenu();

  // Open DevTools in development
  if (process.env.NODE_ENV === 'development') {
    mainWindow.webContents.openDevTools();
  }

  mainWindow.on('closed', () => {
    mainWindow = null;
  });

  logInfo('APP_START', 'Video Editor started');
}

// IPC handler to force focus webContents (workaround for input activation issue)
ipcMain.handle('focus-webcontents', async () => {
  if (mainWindow && mainWindow.webContents) {
    // Simple focus attempt - just return success
    // The real fix will be in the renderer process
    mainWindow.focus();
    mainWindow.webContents.focus();

    return { success: true };
  }
  return { success: false };
});

// Set console encoding to UTF-8 for Windows
if (process.platform === 'win32') {
  try {
    // Try to set console output to UTF-8
    const { execSync } = require('child_process');
    execSync('chcp 65001', { stdio: 'ignore' });
  } catch (e) {
    // Ignore if fails
  }
}

app.whenReady().then(() => {
  ffmpegPath = findFFmpegPath();
  ffprobePath = findFFprobePath();
  console.log('FFmpeg path:', ffmpegPath);
  console.log('FFprobe path:', ffprobePath);
  logInfo('SYSTEM', 'FFmpeg tools found', { ffmpegPath, ffprobePath });
  createWindow();

  app.on('activate', () => {
    if (BrowserWindow.getAllWindows().length === 0) {
      createWindow();
    }
  });
});

app.on('window-all-closed', () => {
  if (process.platform !== 'darwin') {
    app.quit();
  }
});

// Helper function to get video information using ffprobe
function getVideoInfo(videoPath) {
  return new Promise((resolve, reject) => {
    const args = [
      '-v', 'quiet',
      '-print_format', 'json',
      '-show_format',
      '-show_streams',
      videoPath
    ];

    const ffprobe = spawn(ffprobePath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });
    let output = '';
    let errorOutput = '';

    ffprobe.stdout.on('data', (data) => {
      output += data.toString('utf8');
    });

    ffprobe.stderr.on('data', (data) => {
      errorOutput += data.toString('utf8');
    });

    ffprobe.on('close', (code) => {
      if (code === 0) {
        try {
          const info = JSON.parse(output);
          resolve(info);
        } catch (e) {
          reject(new Error('Failed to parse video info'));
        }
      } else {
        reject(new Error(errorOutput || 'FFprobe failed'));
      }
    });

    ffprobe.on('error', (err) => {
      reject(new Error(`FFprobe error: ${err.message}`));
    });
  });
}

// IPC Handlers

// Select video file
ipcMain.handle('select-video', async () => {
  const result = await dialog.showOpenDialog(mainWindow, {
    properties: ['openFile'],
    filters: [
      { name: 'Videos', extensions: ['mp4', 'avi', 'mov', 'mkv', 'webm'] }
    ]
  });

  if (!result.canceled && result.filePaths.length > 0) {
    return result.filePaths[0];
  }
  return null;
});

// Select audio file
ipcMain.handle('select-audio', async () => {
  const result = await dialog.showOpenDialog(mainWindow, {
    properties: ['openFile'],
    filters: [
      { name: 'Audio', extensions: ['mp3', 'wav', 'aac', 'm4a', 'ogg'] }
    ]
  });

  if (!result.canceled && result.filePaths.length > 0) {
    return result.filePaths[0];
  }
  return null;
});

// Select media file (unified: image/video/audio)
ipcMain.handle('select-media', async (event, mediaType) => {
  let filters;

  switch(mediaType) {
    case 'image':
      filters = [
        { name: 'Images', extensions: ['jpg', 'jpeg', 'png', 'gif', 'bmp', 'webp', 'svg'] }
      ];
      break;
    case 'video':
      filters = [
        { name: 'Videos', extensions: ['mp4', 'avi', 'mov', 'mkv', 'webm'] }
      ];
      break;
    case 'audio':
      filters = [
        { name: 'Audio', extensions: ['mp3', 'wav', 'aac', 'm4a', 'ogg'] }
      ];
      break;
    default:
      filters = [
        { name: 'All Media', extensions: ['jpg', 'jpeg', 'png', 'gif', 'bmp', 'webp', 'svg', 'mp4', 'avi', 'mov', 'mkv', 'webm', 'mp3', 'wav', 'aac', 'm4a', 'ogg'] }
      ];
  }

  const result = await dialog.showOpenDialog(mainWindow, {
    properties: ['openFile'],
    filters: filters
  });

  if (!result.canceled && result.filePaths.length > 0) {
    return result.filePaths[0];
  }
  return null;
});

// Select output path
ipcMain.handle('select-output', async (event, defaultName) => {
  logInfo('SELECT_OUTPUT', 'File save dialog requested', { defaultName });

  // Detect file type from default name
  const ext = defaultName ? path.extname(defaultName).toLowerCase() : '.mp4';
  let filters;

  if (ext === '.mp3' || ext === '.wav' || ext === '.aac' || ext === '.ogg') {
    // Audio file
    filters = [
      { name: 'Audio Files', extensions: ['mp3', 'wav', 'aac', 'ogg'] },
      { name: 'All Files', extensions: ['*'] }
    ];
  } else {
    // Video file
    filters = [
      { name: 'Video Files', extensions: ['mp4', 'avi', 'mov', 'mkv', 'webm'] },
      { name: 'All Files', extensions: ['*'] }
    ];
  }

  logInfo('SELECT_OUTPUT', 'Opening save dialog', { defaultPath: defaultName || 'output.mp4', fileType: ext });
  const result = await dialog.showSaveDialog(mainWindow, {
    defaultPath: defaultName || 'output.mp4',
    filters: filters
  });

  logInfo('SELECT_OUTPUT', 'Save dialog result', { canceled: result.canceled, filePath: result.filePath });

  if (!result.canceled) {
    let filePath = result.filePath;

    // Check if file exists and add number suffix if needed
    if (fs.existsSync(filePath)) {
      const dir = path.dirname(filePath);
      const ext = path.extname(filePath);
      const baseName = path.basename(filePath, ext);

      let counter = 1;
      let newFilePath;

      // Find an available filename
      do {
        newFilePath = path.join(dir, `${baseName} (${counter})${ext}`);
        counter++;
      } while (fs.existsSync(newFilePath));

      filePath = newFilePath;
      logInfo('FILE_RENAME', 'File exists, renamed with counter', {
        original: result.filePath,
        renamed: filePath
      });
    }

    return filePath;
  }
  return null;
});

// Get video metadata using FFprobe
ipcMain.handle('get-video-info', async (event, videoPath) => {
  logInfo('VIDEO_INFO_START', 'Getting video information', { videoPath });

  return new Promise((resolve, reject) => {
    const args = [
      '-v', 'quiet',
      '-print_format', 'json',
      '-show_format',
      '-show_streams',
      videoPath
    ];

    logInfo('VIDEO_INFO', 'Running FFprobe', { ffprobePath, args });

    const ffprobe = spawn(ffprobePath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });
    let output = '';
    let errorOutput = '';

    ffprobe.stdout.on('data', (data) => {
      output += data.toString('utf8');
    });

    ffprobe.stderr.on('data', (data) => {
      errorOutput += data.toString('utf8');
    });

    ffprobe.on('close', (code) => {
      if (code === 0) {
        try {
          const info = JSON.parse(output);
          logInfo('VIDEO_INFO_SUCCESS', 'Video information retrieved', {
            duration: info.format.duration,
            size: info.format.size
          });
          resolve(info);
        } catch (e) {
          logError('VIDEO_INFO_FAILED', 'Failed to parse video info', { error: e.message });
          reject(new Error('Failed to parse video info'));
        }
      } else {
        logError('VIDEO_INFO_FAILED', 'FFprobe failed', { code, error: errorOutput });
        reject(new Error(errorOutput || 'FFprobe failed'));
      }
    });

    ffprobe.on('error', (err) => {
      logError('VIDEO_INFO_FAILED', 'FFprobe spawn error', { error: err.message });
      reject(new Error(`FFprobe error: ${err.message}`));
    });
  });
});

// Generate audio waveform image
ipcMain.handle('generate-waveform', async (event, videoPath) => {
  logInfo('WAVEFORM_START', 'Generating audio waveform', { videoPath });

  const path = require('path');
  const os = require('os');

  // Create temp file path for waveform image
  const tempDir = os.tmpdir();
  const waveformPath = path.join(tempDir, `waveform_${Date.now()}.png`);

  return new Promise((resolve, reject) => {
    // Generate waveform using FFmpeg showwavespic filter
    // draw=scale - draws a center line for silent parts
    // scale=lin - linear scale for better visibility
    // split_channels=1 - separate stereo channels (L/R) vertically
    const args = [
      '-i', videoPath,
      '-filter_complex',
      '[0:a]showwavespic=s=1200x300:colors=#667eea:draw=scale:scale=log:split_channels=1[wave]',
      '-map', '[wave]',
      '-frames:v', '1',
      '-y',
      waveformPath
    ];

    const ffmpeg = spawn(ffmpegPath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });
    let errorOutput = '';

    ffmpeg.stderr.on('data', (data) => {
      errorOutput += data.toString('utf8');
    });

    ffmpeg.on('close', (code) => {
      if (code === 0) {
        try {
          // Read the generated PNG and convert to base64
          const imageBuffer = fs.readFileSync(waveformPath);
          const base64Image = `data:image/png;base64,${imageBuffer.toString('base64')}`;

          // Clean up temp file
          try {
            fs.unlinkSync(waveformPath);
          } catch (cleanupErr) {
            logError('WAVEFORM_CLEANUP', 'Failed to delete temp waveform file', { error: cleanupErr.message });
          }

          logInfo('WAVEFORM_SUCCESS', 'Waveform generated and converted to base64', { length: base64Image.length });
          resolve(base64Image);
        } catch (readErr) {
          logError('WAVEFORM_READ_FAILED', 'Failed to read waveform file', { error: readErr.message });
          reject(new Error(`Failed to read waveform: ${readErr.message}`));
        }
      } else {
        logError('WAVEFORM_FAILED', 'Waveform generation failed', { error: errorOutput });
        reject(new Error(errorOutput || 'FFmpeg waveform generation failed'));
      }
    });

    ffmpeg.on('error', (err) => {
      logError('WAVEFORM_FAILED', 'FFmpeg spawn error', { error: err.message });
      reject(new Error(`FFmpeg error: ${err.message}`));
    });
  });
});

// Generate waveform for a specific time range (for zoom)
ipcMain.handle('generate-waveform-range', async (event, options) => {
  const { videoPath, startTime, duration } = options;

  logInfo('WAVEFORM_RANGE_START', 'Generating waveform for time range', {
    videoPath,
    startTime,
    duration
  });

  const path = require('path');
  const os = require('os');

  // First, check if the file has an audio stream
  const hasAudio = await new Promise((resolve) => {
    const ffprobe = spawn(ffprobePath, [
      '-v', 'error',
      '-select_streams', 'a:0',
      '-show_entries', 'stream=codec_type',
      '-of', 'default=noprint_wrappers=1:nokey=1',
      videoPath
    ], {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });

    let output = '';
    ffprobe.stdout.on('data', (data) => {
      output += data.toString('utf8');
    });

    ffprobe.on('close', (code) => {
      const hasAudioStream = output.trim() === 'audio';
      resolve(hasAudioStream);
    });
  });

  if (!hasAudio) {
    logError('WAVEFORM_RANGE_NO_AUDIO', 'No audio stream found in video', { videoPath });
    return Promise.reject(new Error('No audio stream found in video file'));
  }

  // Create temp file path for waveform image
  const tempDir = os.tmpdir();
  const waveformPath = path.join(tempDir, `waveform_range_${Date.now()}.png`);

  return new Promise((resolve, reject) => {
    // Generate waveform for specific time range using FFmpeg
    // Use atrim filter to precisely trim audio before generating waveform
    const endTime = startTime + duration;
    const args = [
      '-i', videoPath,
      '-filter_complex',
      `[0:a]atrim=start=${startTime}:end=${endTime},asetpts=PTS-STARTPTS[trimmed];[trimmed]showwavespic=s=1200x300:colors=#667eea:draw=scale:scale=log:split_channels=1[wave]`,
      '-map', '[wave]',
      '-frames:v', '1',
      '-y',
      waveformPath
    ];

    const ffmpeg = spawn(ffmpegPath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });
    let errorOutput = '';

    ffmpeg.stderr.on('data', (data) => {
      errorOutput += data.toString('utf8');
    });

    ffmpeg.on('close', (code) => {
      if (code === 0) {
        try {
          // Read the generated PNG and convert to base64
          const imageBuffer = fs.readFileSync(waveformPath);
          const base64Image = `data:image/png;base64,${imageBuffer.toString('base64')}`;

          // Clean up temp file
          try {
            fs.unlinkSync(waveformPath);
          } catch (cleanupErr) {
            logError('WAVEFORM_RANGE_CLEANUP', 'Failed to delete temp waveform file', {
              error: cleanupErr.message
            });
          }

          logInfo('WAVEFORM_RANGE_SUCCESS', 'Range waveform generated', {
            length: base64Image.length,
            startTime,
            duration
          });
          resolve(base64Image);
        } catch (readErr) {
          logError('WAVEFORM_RANGE_READ_FAILED', 'Failed to read waveform file', {
            error: readErr.message
          });
          reject(new Error(`Failed to read waveform: ${readErr.message}`));
        }
      } else {
        logError('WAVEFORM_RANGE_FAILED', 'Waveform range generation failed', {
          error: errorOutput
        });
        reject(new Error(errorOutput || 'FFmpeg waveform range generation failed'));
      }
    });

    ffmpeg.on('error', (err) => {
      logError('WAVEFORM_RANGE_FAILED', 'FFmpeg spawn error', { error: err.message });
      reject(new Error(`FFmpeg error: ${err.message}`));
    });
  });
});

// Generate waveform from URL (download first, then generate)
ipcMain.handle('generate-waveform-from-url', async (event, videoUrl) => {
  logInfo('WAVEFORM_URL_START', 'Generating waveform from URL', { videoUrl });

  const https = require('https');
  const http = require('http');
  const path = require('path');
  const os = require('os');
  const tempDir = os.tmpdir();
  const tempVideoPath = path.join(tempDir, `veo_video_${Date.now()}.mp4`);
  const waveformPath = path.join(tempDir, `waveform_${Date.now()}.png`);

  try {
    // Download video to temp file
    logInfo('WAVEFORM_URL_DOWNLOAD', 'Downloading video', { videoUrl, tempVideoPath });

    await new Promise((resolve, reject) => {
      const file = fs.createWriteStream(tempVideoPath);

      // Check if this is a Google API URL
      if (videoUrl.includes('generativelanguage.googleapis.com')) {
        const axios = require('axios');
        const apiKey = process.env.GOOGLE_AI_API_KEY;

        if (!apiKey) {
          reject(new Error('GOOGLE_AI_API_KEY environment variable not set'));
          return;
        }

        // Add API key as query parameter
        const separator = videoUrl.includes('?') ? '&' : '?';
        const downloadUrl = `${videoUrl}${separator}key=${apiKey}`;

        axios({
          method: 'GET',
          url: downloadUrl,
          responseType: 'stream',
          headers: { 'x-goog-api-key': apiKey },
          timeout: 300000
        }).then((response) => {
          response.data.pipe(file);

          file.on('finish', () => {
            file.close();
            resolve();
          });

          file.on('error', (err) => {
            fs.unlinkSync(tempVideoPath);
            reject(err);
          });
        }).catch((err) => {
          reject(err);
        });
      } else {
        // Regular HTTP/HTTPS download
        const protocol = videoUrl.startsWith('https') ? https : http;

        protocol.get(videoUrl, (response) => {
          if (response.statusCode !== 200) {
            reject(new Error(`Failed to download: ${response.statusCode}`));
            return;
          }

          response.pipe(file);

          file.on('finish', () => {
            file.close();
            resolve();
          });

          file.on('error', (err) => {
            fs.unlinkSync(tempVideoPath);
            reject(err);
          });
        }).on('error', (err) => {
          reject(err);
        });
      }
    });

    logInfo('WAVEFORM_URL_DOWNLOADED', 'Video downloaded, generating waveform');

    // Generate waveform using FFmpeg
    const base64Image = await new Promise((resolve, reject) => {
      const args = [
        '-i', tempVideoPath,
        '-filter_complex',
        '[0:a]showwavespic=s=1200x300:colors=#667eea:draw=scale:scale=log:split_channels=1[wave]',
        '-map', '[wave]',
        '-frames:v', '1',
        '-y',
        waveformPath
      ];

      const ffmpeg = spawn(ffmpegPath, args, {
        stdio: ['pipe', 'pipe', 'pipe'],
        windowsHide: true
      });

      let errorOutput = '';
      ffmpeg.stderr.on('data', (data) => {
        errorOutput += data.toString('utf8');
      });

      ffmpeg.on('close', (code) => {
        if (code === 0) {
          try {
            const imageBuffer = fs.readFileSync(waveformPath);
            const base64 = `data:image/png;base64,${imageBuffer.toString('base64')}`;

            // Clean up temp files
            try {
              fs.unlinkSync(waveformPath);
            } catch (e) {}
            try {
              fs.unlinkSync(tempVideoPath);
            } catch (e) {}

            logInfo('WAVEFORM_URL_SUCCESS', 'Waveform generated from URL');
            resolve(base64);
          } catch (readErr) {
            reject(new Error(`Failed to read waveform: ${readErr.message}`));
          }
        } else {
          logError('WAVEFORM_URL_FAILED', 'Waveform generation failed', { error: errorOutput });
          reject(new Error(errorOutput || 'FFmpeg waveform generation failed'));
        }
      });

      ffmpeg.on('error', (err) => {
        reject(new Error(`FFmpeg error: ${err.message}`));
      });
    });

    return base64Image;
  } catch (error) {
    logError('WAVEFORM_URL_ERROR', 'Error generating waveform from URL', { error: error.message });

    // Clean up temp files on error
    try {
      if (fs.existsSync(tempVideoPath)) fs.unlinkSync(tempVideoPath);
    } catch (e) {}
    try {
      if (fs.existsSync(waveformPath)) fs.unlinkSync(waveformPath);
    } catch (e) {}

    throw error;
  }
});

// Trim video
ipcMain.handle('trim-video', async (event, options) => {
  let { inputPath, outputPath, startTime, duration } = options;

  // If outputPath is null, create temp file
  if (!outputPath) {
    const os = require('os');
    const tempDir = os.tmpdir();
    const timestamp = Date.now();
    const fileName = path.basename(inputPath, path.extname(inputPath));
    outputPath = path.join(tempDir, `${fileName}_trimmed_${timestamp}.mp4`);
  }

  logInfo('TRIM_START', 'Starting video trim', { inputPath, outputPath, startTime, duration });

  // Check if input has audio stream
  const hasAudio = await new Promise((resolve) => {
    const ffprobe = spawn(ffprobePath, [
      '-v', 'error',
      '-select_streams', 'a:0',
      '-show_entries', 'stream=codec_type',
      '-of', 'default=noprint_wrappers=1:nokey=1',
      inputPath
    ], {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });

    let output = '';
    ffprobe.stdout.on('data', (data) => {
      output += data.toString('utf8');
    });

    ffprobe.on('close', (code) => {
      const audioExists = output.trim() === 'audio';
      resolve(audioExists);
    });
  });

  return new Promise((resolve, reject) => {
    // Build args based on audio presence
    // IMPORTANT: Put -ss BEFORE -i for faster and more accurate seeking
    const args = [
      '-ss', startTime.toString(),  // Seek before input (faster, more accurate)
      '-i', inputPath,
      '-t', duration.toString(),     // Duration after input
      '-map', '0:v',                 // Map video stream
    ];

    // Add audio mapping only if audio exists
    if (hasAudio) {
      args.push('-map', '0:a');      // Map audio stream
      args.push('-c:v', 'copy');     // Copy video codec
      args.push('-c:a', 'aac');      // Re-encode audio to AAC
      args.push('-b:a', '192k');     // Audio bitrate
      args.push('-ar', '48000');     // Sample rate (48000Hz for higher quality)
      args.push('-ac', '2');         // Stereo channels
    } else {
      args.push('-c:v', 'copy');     // Copy video codec only
      logInfo('TRIM_NO_AUDIO', 'Input has no audio, video only trim', { inputPath });
    }

    args.push('-y', outputPath);

    logInfo('TRIM_FFMPEG_CMD', 'FFmpeg trim command', { hasAudio, args: args.join(' ') });

    const ffmpeg = spawn(ffmpegPath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });
    let errorOutput = '';

    ffmpeg.stderr.on('data', (data) => {
      const message = data.toString('utf8');
      errorOutput += message;

      // Send progress updates
      mainWindow.webContents.send('ffmpeg-progress', message);
    });

    ffmpeg.on('close', (code) => {
      if (code === 0) {
        logInfo('TRIM_SUCCESS', 'Video trim completed', { outputPath, hasAudio });
        resolve({ success: true, outputPath });
      } else {
        logError('TRIM_FAILED', 'Video trim failed', { error: errorOutput });
        reject(new Error(errorOutput || 'FFmpeg failed'));
      }
    });
  });
});

// Re-encode video with quality and resolution settings
ipcMain.handle('re-encode-video', async (event, options) => {
  const { inputPath, qualitySettings } = options;

  // Create temp file for output
  const os = require('os');
  const tempDir = os.tmpdir();
  const timestamp = Date.now();
  const fileName = path.basename(inputPath, path.extname(inputPath));
  const outputPath = path.join(tempDir, `${fileName}_reencoded_${timestamp}.mp4`);

  logInfo('REENCODE_START', 'Starting video re-encoding', { inputPath, outputPath, qualitySettings });

  // Check if input has audio stream
  const hasAudio = await new Promise((resolve) => {
    const ffprobe = spawn(ffprobePath, [
      '-v', 'error',
      '-select_streams', 'a:0',
      '-show_entries', 'stream=codec_type',
      '-of', 'default=noprint_wrappers=1:nokey=1',
      inputPath
    ], {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });

    let output = '';
    ffprobe.stdout.on('data', (data) => {
      output += data.toString('utf8');
    });

    ffprobe.on('close', (code) => {
      const audioExists = output.trim() === 'audio';
      resolve(audioExists);
    });
  });

  return new Promise((resolve, reject) => {
    // Build FFmpeg args with quality settings
    const args = [
      '-i', inputPath
    ];

    // Build video filters array
    const videoFilters = [];

    // Add resolution scaling filter
    if (qualitySettings.resolution && qualitySettings.resolution.width && qualitySettings.resolution.height) {
      videoFilters.push(`scale=${qualitySettings.resolution.width}:${qualitySettings.resolution.height}:force_original_aspect_ratio=decrease`);
    }

    // Add FPS filter
    if (qualitySettings.fps && qualitySettings.fps.fps) {
      videoFilters.push(`fps=${qualitySettings.fps.fps}`);
    }

    // Apply video filters if any
    if (videoFilters.length > 0) {
      args.push('-vf', videoFilters.join(','));
    }

    // Video codec and quality settings
    args.push(
      '-c:v', 'libx264',                         // H.264 codec
      '-crf', qualitySettings.quality.crf.toString(),  // CRF value (quality)
      '-preset', qualitySettings.quality.preset,  // Encoding preset (speed vs compression)
      '-pix_fmt', 'yuv420p'                      // Pixel format for compatibility
    );

    // Add FPS output flag if specified
    if (qualitySettings.fps && qualitySettings.fps.fps) {
      args.push('-r', qualitySettings.fps.fps.toString());
    }

    // Audio settings (only if audio exists)
    if (hasAudio) {
      args.push(
        '-c:a', 'aac',      // AAC audio codec
        '-b:a', '192k',     // Audio bitrate
        '-ar', '48000',     // Sample rate
        '-ac', '2'          // Stereo channels
      );
      logInfo('REENCODE_AUDIO', 'Re-encoding with audio', { hasAudio });
    } else {
      args.push('-an');  // No audio
      logInfo('REENCODE_NO_AUDIO', 'Re-encoding video only (no audio)', { hasAudio });
    }

    args.push('-y', outputPath);

    logInfo('REENCODE_FFMPEG_CMD', 'FFmpeg re-encode command', {
      hasAudio,
      args: args.join(' '),
      quality: qualitySettings.quality,
      resolution: qualitySettings.resolution,
      fps: qualitySettings.fps
    });

    const ffmpeg = spawn(ffmpegPath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });

    let errorOutput = '';

    ffmpeg.stderr.on('data', (data) => {
      const message = data.toString('utf8');
      errorOutput += message;

      // Send progress updates
      mainWindow.webContents.send('ffmpeg-progress', message);
    });

    ffmpeg.on('close', (code) => {
      if (code === 0) {
        logInfo('REENCODE_SUCCESS', 'Video re-encoding completed', { outputPath, hasAudio });
        resolve({ success: true, outputPath });
      } else {
        logError('REENCODE_FAILED', 'Video re-encoding failed', { error: errorOutput });
        reject(new Error(errorOutput || 'FFmpeg re-encoding failed'));
      }
    });
  });
});

// Trim video only (delete selected range from video, trim audio from end)
ipcMain.handle('trim-video-only', async (event, options) => {
  let { inputPath, outputPath, startTime, duration } = options;

  // If outputPath is null, create temp file
  if (!outputPath) {
    const os = require('os');
    const tempDir = os.tmpdir();
    const timestamp = Date.now();
    const fileName = path.basename(inputPath, path.extname(inputPath));
    outputPath = path.join(tempDir, `${fileName}_trimmed_video_only_${timestamp}.mp4`);
  }

  logInfo('TRIM_VIDEO_ONLY_START', 'Starting video-only trim (delete range)', { inputPath, outputPath, startTime, duration });

  // Check if input and output are the same file
  const isSameFile = path.resolve(inputPath) === path.resolve(outputPath);

  // If same file, create temp file with proper extension
  let actualOutputPath = outputPath;
  if (isSameFile) {
    const ext = path.extname(outputPath);
    const base = outputPath.slice(0, -ext.length);
    actualOutputPath = `${base}_temp_${Date.now()}${ext}`;
    logInfo('TRIM_VIDEO_ONLY_SAME_FILE', 'Same file detected, using temp file', { actualOutputPath });
  }

  // Get video duration using ffprobe
  const getVideoDuration = () => {
    return new Promise((resolve) => {
      const ffprobe = spawn(ffprobePath, [
        '-v', 'error',
        '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        inputPath
      ], { stdio: ['pipe', 'pipe', 'pipe'], windowsHide: true });

      let output = '';
      ffprobe.stdout.on('data', (data) => { output += data.toString('utf8'); });
      ffprobe.on('close', () => { resolve(parseFloat(output.trim()) || 0); });
    });
  };

  return new Promise(async (resolve, reject) => {
    const videoDuration = await getVideoDuration();
    const endTime = startTime + duration;
    const finalDuration = videoDuration - duration;

    // Delete selected range from video, trim audio from end
    // Video: concat 0~startTime and endTime~videoDuration
    // Audio: trim to 0~finalDuration
    const filterComplex = [
      `[0:v]trim=start=0:end=${startTime},setpts=PTS-STARTPTS[v1]`,
      `[0:v]trim=start=${endTime},setpts=PTS-STARTPTS[v2]`,
      `[v1][v2]concat=n=2:v=1:a=0[vout]`,
      `[0:a]atrim=0:${finalDuration},asetpts=PTS-STARTPTS[aout]`
    ].join(';');

    const args = [
      '-i', inputPath,
      '-filter_complex', filterComplex,
      '-map', '[vout]',
      '-map', '[aout]',
      '-c:v', 'libx264',
      '-c:a', 'aac',
      '-b:a', '192k',
      '-ar', '48000',
      '-ac', '2',
      '-y',
      actualOutputPath
    ];

    logInfo('TRIM_VIDEO_ONLY_FFMPEG_CMD', 'FFmpeg command for video-only trim', { filterComplex });

    const ffmpeg = spawn(ffmpegPath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });
    let errorOutput = '';

    ffmpeg.stderr.on('data', (data) => {
      const message = data.toString('utf8');
      errorOutput += message;
      mainWindow.webContents.send('ffmpeg-progress', message);
    });

    ffmpeg.on('close', (code) => {
      if (code === 0) {
        // If we used a temp file, replace the original
        if (isSameFile) {
          try {
            if (fs.existsSync(outputPath)) {
              fs.unlinkSync(outputPath);
            }
            fs.renameSync(actualOutputPath, outputPath);
            logInfo('TRIM_VIDEO_ONLY_SUCCESS', 'Video-only trim completed, temp file replaced', { outputPath, finalDuration });
          } catch (err) {
            logError('TRIM_VIDEO_ONLY_REPLACE_FAILED', 'Failed to replace original file', { error: err.message });
            reject(new Error(`Failed to replace file: ${err.message}`));
            return;
          }
        } else {
          logInfo('TRIM_VIDEO_ONLY_SUCCESS', 'Video-only trim completed', { outputPath, finalDuration });
        }
        resolve({ success: true, outputPath });
      } else {
        // Clean up temp file if it exists
        if (isSameFile && fs.existsSync(actualOutputPath)) {
          try {
            fs.unlinkSync(actualOutputPath);
          } catch (err) {
            logError('TRIM_VIDEO_ONLY_CLEANUP_FAILED', 'Failed to clean up temp file', { error: err.message });
          }
        }
        logError('TRIM_VIDEO_ONLY_FAILED', 'Video-only trim failed', { error: errorOutput });
        reject(new Error(errorOutput || 'FFmpeg failed'));
      }
    });

    ffmpeg.on('error', (err) => {
      // Clean up temp file if it exists
      if (isSameFile && fs.existsSync(actualOutputPath)) {
        try {
          fs.unlinkSync(actualOutputPath);
        } catch (cleanupErr) {
          logError('TRIM_VIDEO_ONLY_CLEANUP_FAILED', 'Failed to clean up temp file', { error: cleanupErr.message });
        }
      }
      logError('TRIM_VIDEO_ONLY_FAILED', 'FFmpeg spawn error', { error: err.message });
      reject(new Error(`FFmpeg error: ${err.message}`));
    });
  });
});

// Trim audio only (keep video intact)
ipcMain.handle('trim-audio-only', async (event, options) => {
  let { inputPath, outputPath, startTime, endTime } = options;

  // If outputPath is null, create temp file
  if (!outputPath) {
    const os = require('os');
    const tempDir = os.tmpdir();
    const timestamp = Date.now();
    const fileName = path.basename(inputPath, path.extname(inputPath));
    outputPath = path.join(tempDir, `${fileName}_trimmed_audio_only_${timestamp}.mp4`);
  }

  logInfo('TRIM_AUDIO_ONLY_START', 'Starting audio-only trim', { inputPath, outputPath, startTime, endTime });

  // Check if input and output are the same file
  const isSameFile = path.resolve(inputPath) === path.resolve(outputPath);

  // If same file, create temp file with proper extension
  let actualOutputPath = outputPath;
  if (isSameFile) {
    const ext = path.extname(outputPath);
    const base = outputPath.slice(0, -ext.length);
    actualOutputPath = `${base}_temp_${Date.now()}${ext}`;
    logInfo('TRIM_AUDIO_ONLY_SAME_FILE', 'Same file detected, using temp file', { actualOutputPath });
  }

  // Get video duration using ffprobe
  const getVideoDuration = () => {
    return new Promise((resolve) => {
      const ffprobe = spawn(ffprobePath, [
        '-v', 'error',
        '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        inputPath
      ], { stdio: ['pipe', 'pipe', 'pipe'], windowsHide: true });

      let output = '';
      ffprobe.stdout.on('data', (data) => { output += data.toString('utf8'); });
      ffprobe.on('close', () => { resolve(parseFloat(output.trim()) || 0); });
    });
  };

  return new Promise(async (resolve, reject) => {
    const videoDuration = await getVideoDuration();
    const deleteDuration = endTime - startTime;

    // Delete selected range from audio: concat 0~startTime and endTime~end, then pad with silence
    // Audio: concat before and after, then pad to video duration
    const filterComplex = [
      `[0:a]atrim=0:${startTime},asetpts=PTS-STARTPTS[a1]`,
      `[0:a]atrim=${endTime},asetpts=PTS-STARTPTS[a2]`,
      `[a1][a2]concat=n=2:v=0:a=1,apad=whole_dur=${videoDuration}[aout]`
    ].join(';');

    const args = [
      '-i', inputPath,
      '-filter_complex', filterComplex,
      '-map', '0:v',    // Map video stream (copy completely)
      '-map', '[aout]', // Map filtered and padded audio
      '-c:v', 'copy',   // Copy video without modification
      '-c:a', 'aac',    // Encode filtered audio
      '-b:a', '192k',
      '-ar', '48000',
      '-ac', '2',
      '-y',
      actualOutputPath
    ];

    logInfo('TRIM_AUDIO_ONLY_FFMPEG_CMD', 'FFmpeg command for audio-only trim', { filterComplex });

    const ffmpeg = spawn(ffmpegPath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });
    let errorOutput = '';

    ffmpeg.stderr.on('data', (data) => {
      const message = data.toString('utf8');
      errorOutput += message;
      mainWindow.webContents.send('ffmpeg-progress', message);
    });

    ffmpeg.on('close', (code) => {
      if (code === 0) {
        // If we used a temp file, replace the original
        if (isSameFile) {
          try {
            if (fs.existsSync(outputPath)) {
              fs.unlinkSync(outputPath);
            }
            fs.renameSync(actualOutputPath, outputPath);
            logInfo('TRIM_AUDIO_ONLY_SUCCESS', 'Audio-only trim completed (delete range), temp file replaced', { outputPath, videoDuration });
          } catch (err) {
            logError('TRIM_AUDIO_ONLY_REPLACE_FAILED', 'Failed to replace original file', { error: err.message });
            reject(new Error(`Failed to replace file: ${err.message}`));
            return;
          }
        } else {
          logInfo('TRIM_AUDIO_ONLY_SUCCESS', 'Audio-only trim completed (delete range, padded to video duration)', { outputPath, videoDuration });
        }
        resolve({ success: true, outputPath });
      } else {
        // Clean up temp file if it exists
        if (isSameFile && fs.existsSync(actualOutputPath)) {
          try {
            fs.unlinkSync(actualOutputPath);
          } catch (err) {
            logError('TRIM_AUDIO_ONLY_CLEANUP_FAILED', 'Failed to clean up temp file', { error: err.message });
          }
        }
        logError('TRIM_AUDIO_ONLY_FAILED', 'Audio-only trim failed', { error: errorOutput });
        reject(new Error(errorOutput || 'FFmpeg failed'));
      }
    });

    ffmpeg.on('error', (err) => {
      // Clean up temp file if it exists
      if (isSameFile && fs.existsSync(actualOutputPath)) {
        try {
          fs.unlinkSync(actualOutputPath);
        } catch (cleanupErr) {
          logError('TRIM_AUDIO_ONLY_CLEANUP_FAILED', 'Failed to clean up temp file', { error: cleanupErr.message });
        }
      }
      logError('TRIM_AUDIO_ONLY_FAILED', 'FFmpeg spawn error', { error: err.message });
      reject(new Error(`FFmpeg error: ${err.message}`));
    });
  });
});

// Adjust audio volume (audio-only files)
ipcMain.handle('adjust-audio-volume', async (event, options) => {
  const { inputPath, outputPath, volumeLevel } = options;

  logInfo('ADJUST_AUDIO_VOLUME_START', 'Starting audio volume adjustment', { inputPath, outputPath, volumeLevel });

  // If outputPath is null, create temp file
  let actualOutputPath = outputPath;
  if (!actualOutputPath) {
    const os = require('os');
    const tempDir = os.tmpdir();
    const timestamp = Date.now();
    const fileName = path.basename(inputPath, path.extname(inputPath));
    // Always use .mp4 extension for video output (input might be .tmp)
    actualOutputPath = path.join(tempDir, `${fileName}_volume_${volumeLevel}x_${timestamp}.mp4`);
    logInfo('ADJUST_AUDIO_VOLUME_TEMP', 'Creating temp file', { actualOutputPath });
  }

  return new Promise((resolve, reject) => {
    const args = [
      '-i', inputPath,
      '-af', `volume=${volumeLevel}`,
      '-c:v', 'copy',  // Copy video stream without re-encoding
      '-c:a', 'aac',  // Use AAC encoder for audio (MP4 compatible)
      '-b:a', '192k',  // Bitrate
      '-f', 'mp4',  // Explicitly specify MP4 format
      '-y',  // Overwrite output file
      actualOutputPath
    ];

    logInfo('ADJUST_AUDIO_VOLUME_COMMAND', 'Executing FFmpeg command', { ffmpegPath, args });

    const ffmpeg = spawn(ffmpegPath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });

    let stderrOutput = '';

    ffmpeg.stdout.on('data', (data) => {
      const message = data.toString('utf8');
      logInfo('ADJUST_AUDIO_VOLUME_STDOUT', 'FFmpeg stdout', { message: message.trim() });
      mainWindow.webContents.send('ffmpeg-progress', message);
    });

    ffmpeg.stderr.on('data', (data) => {
      const message = data.toString('utf8');
      stderrOutput += message;
      logInfo('ADJUST_AUDIO_VOLUME_STDERR', 'FFmpeg stderr', { message: message.trim() });
      mainWindow.webContents.send('ffmpeg-progress', message);
    });

    ffmpeg.on('close', (code) => {
      if (code === 0) {
        logInfo('ADJUST_AUDIO_VOLUME_SUCCESS', 'Audio volume adjustment completed', { outputPath: actualOutputPath, code });
        resolve({ outputPath: actualOutputPath, success: true });
      } else {
        logError('ADJUST_AUDIO_VOLUME_FAILED', 'FFmpeg exited with non-zero code', { code, stderr: stderrOutput });
        reject(new Error(stderrOutput || `FFmpeg exited with code ${code}`));
      }
    });

    ffmpeg.on('error', (err) => {
      logError('ADJUST_AUDIO_VOLUME_ERROR', 'FFmpeg spawn error', { error: err.message });
      reject(new Error(`FFmpeg error: ${err.message}`));
    });
  });
});

// Add audio to video
ipcMain.handle('add-audio', async (event, options) => {
  let { videoPath, audioPath, outputPath, volumeLevel, audioStartTime, isSilence, silenceDuration, insertMode } = options;

  // If outputPath is null, create temp file
  if (!outputPath) {
    const os = require('os');
    const tempDir = os.tmpdir();
    const timestamp = Date.now();
    const fileName = path.basename(videoPath, path.extname(videoPath));
    outputPath = path.join(tempDir, `${fileName}_with_audio_${timestamp}.mp4`);
  }

  logInfo('ADD_AUDIO_START', 'Starting audio addition', { videoPath, audioPath, outputPath, volumeLevel, audioStartTime, isSilence, silenceDuration, insertMode });

  // First, check if video has audio stream
  const checkAudio = () => {
    return new Promise((resolve) => {
      const ffprobe = spawn(ffprobePath, [
        '-v', 'error',
        '-select_streams', 'a:0',
        '-show_entries', 'stream=codec_type',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        videoPath
      ], {
        stdio: ['pipe', 'pipe', 'pipe'],
        windowsHide: true
      });

      let output = '';
      let errorOutput = '';

      ffprobe.stdout.on('data', (data) => {
        output += data.toString('utf8');
      });

      ffprobe.stderr.on('data', (data) => {
        errorOutput += data.toString('utf8');
      });

      ffprobe.on('close', (code) => {
        const hasAudio = output.trim() === 'audio';
        resolve(hasAudio);
      });
    });
  };

  return new Promise(async (resolve, reject) => {
    try {
      // Check if input and output are the same file
      const isSameFile = path.resolve(videoPath) === path.resolve(outputPath);

      // If same file, create temp file with proper extension
      let actualOutputPath = outputPath;
      if (isSameFile) {
        const ext = path.extname(outputPath);
        const base = outputPath.slice(0, -ext.length);
        actualOutputPath = `${base}_temp_${Date.now()}${ext}`;
      }

      const hasAudio = await checkAudio();

      let args;
      const startTimeMs = (audioStartTime || 0) * 1000; // Convert to milliseconds

      // Handle silence insertion
      if (isSilence) {
        const mode = insertMode || 'mix';

        if (hasAudio) {
          if (mode === 'overwrite') {
            // Overwrite mode: Replace audio segment with silence
            const endTime = audioStartTime + silenceDuration;

            // Get video duration to ensure audio matches video length
            const getVideoDuration = () => {
              return new Promise((resolve) => {
                const ffprobe = spawn(ffprobePath, [
                  '-v', 'error',
                  '-show_entries', 'format=duration',
                  '-of', 'default=noprint_wrappers=1:nokey=1',
                  videoPath
                ], { stdio: ['pipe', 'pipe', 'pipe'], windowsHide: true });

                let output = '';
                ffprobe.stdout.on('data', (data) => { output += data.toString('utf8'); });
                ffprobe.on('close', () => { resolve(parseFloat(output.trim()) || 0); });
              });
            };

            const videoDuration = await getVideoDuration();

            args = [
              '-i', videoPath,
              '-f', 'lavfi',
              '-i', `anullsrc=r=44100:cl=stereo:d=${silenceDuration}`,
              '-filter_complex',
              `[0:a]aselect='lt(t,${audioStartTime})',asetpts=N/SR/TB[before];` +
              `[0:a]aselect='gte(t,${endTime})',asetpts=N/SR/TB[after];` +
              `[before][1:a][after]concat=n=3:v=0:a=1,apad=whole_dur=${videoDuration}[aout]`,
              '-map', '0:v',
              '-map', '[aout]',
              '-c:v', 'copy',
              '-c:a', 'aac',
              '-y',
              actualOutputPath
            ];
          } else if (mode === 'push') {
            // Push mode: Insert silence and push existing audio backward
            args = [
              '-i', videoPath,
              '-f', 'lavfi',
              '-i', `anullsrc=r=44100:cl=stereo:d=${silenceDuration}`,
              '-filter_complex',
              `[0:a]aselect='lt(t,${audioStartTime})',asetpts=N/SR/TB[before];` +
              `[0:a]aselect='gte(t,${audioStartTime})',asetpts=N/SR/TB[after];` +
              `[before][1:a][after]concat=n=3:v=0:a=1[aout]`,
              '-map', '0:v',
              '-map', '[aout]',
              '-c:v', 'copy',
              '-c:a', 'aac',
              '-y',
              actualOutputPath
            ];
          } else {
            // Mix mode (default): Mix silence with existing audio (effectively mutes that section)
            // Get video duration to ensure output matches video length
            const getVideoDuration = () => {
              return new Promise((resolve) => {
                const ffprobe = spawn(ffprobePath, [
                  '-v', 'error',
                  '-show_entries', 'format=duration',
                  '-of', 'default=noprint_wrappers=1:nokey=1',
                  videoPath
                ], { stdio: ['pipe', 'pipe', 'pipe'], windowsHide: true });

                let output = '';
                ffprobe.stdout.on('data', (data) => { output += data.toString('utf8'); });
                ffprobe.on('close', () => { resolve(parseFloat(output.trim()) || 0); });
              });
            };

            const videoDuration = await getVideoDuration();

            args = [
              '-i', videoPath,
              '-f', 'lavfi',
              '-i', `anullsrc=r=44100:cl=stereo:d=${silenceDuration}`,
              '-filter_complex', `[1:a]adelay=${startTimeMs}|${startTimeMs}[a1];[0:a][a1]amix=inputs=2:duration=first:dropout_transition=0,volume=1,apad=whole_dur=${videoDuration}[aout]`,
              '-map', '0:v',
              '-map', '[aout]',
              '-c:v', 'copy',
              '-c:a', 'aac',
              '-y',
              actualOutputPath
            ];
          }
        } else {
          // Video has no audio - add silence as new track
          // Get video duration and pad audio to match
          const getVideoDuration = () => {
            return new Promise((resolve) => {
              const ffprobe = spawn(ffprobePath, [
                '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                videoPath
              ], { stdio: ['pipe', 'pipe', 'pipe'], windowsHide: true });

              let output = '';
              ffprobe.stdout.on('data', (data) => { output += data.toString('utf8'); });
              ffprobe.on('close', () => { resolve(parseFloat(output.trim()) || 0); });
            });
          };

          const videoDuration = await getVideoDuration();

          args = [
            '-f', 'lavfi',
            '-i', `anullsrc=r=44100:cl=stereo:d=${silenceDuration}`,
            '-i', videoPath,
            '-filter_complex', `[0:a]adelay=${startTimeMs}|${startTimeMs},apad=whole_dur=${videoDuration}[a1]`,
            '-map', '1:v',
            '-map', '[a1]',
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-y',
            actualOutputPath
          ];
        }
      } else if (hasAudio) {
        // Video has audio - handle based on insert mode
        const mode = insertMode || 'mix'; // Default to mix if not specified

        if (mode === 'mix') {
          // Mix: Combine existing audio with new audio
          // Get video duration to ensure output matches video length
          const getVideoDuration = () => {
            return new Promise((resolve) => {
              const ffprobe = spawn(ffprobePath, [
                '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                videoPath
              ], { stdio: ['pipe', 'pipe', 'pipe'], windowsHide: true });

              let output = '';
              ffprobe.stdout.on('data', (data) => { output += data.toString('utf8'); });
              ffprobe.on('close', () => { resolve(parseFloat(output.trim()) || 0); });
            });
          };

          const videoDuration = await getVideoDuration();

          args = [
            '-i', videoPath,
            '-i', audioPath,
            '-filter_complex', `[1:a]volume=${volumeLevel},adelay=${startTimeMs}|${startTimeMs}[a1];[0:a][a1]amix=inputs=2:duration=first:dropout_transition=2,apad=whole_dur=${videoDuration}[aout]`,
            '-map', '0:v',
            '-map', '[aout]',
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-y',
            actualOutputPath
          ];
        } else if (mode === 'overwrite') {
          // Overwrite: Replace audio in specified range with new audio
          // Get audio duration and video duration
          const getDuration = (path) => {
            return new Promise((resolve) => {
              const ffprobe = spawn(ffprobePath, [
                '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                path
              ], { stdio: ['pipe', 'pipe', 'pipe'], windowsHide: true });

              let output = '';
              ffprobe.stdout.on('data', (data) => { output += data.toString('utf8'); });
              ffprobe.on('close', () => { resolve(parseFloat(output.trim()) || 0); });
            });
          };

          const audioDuration = await getDuration(audioPath);
          const videoDuration = await getDuration(videoPath);
          const endTime = audioStartTime + audioDuration;

          // Complex filter: extract before/after segments and insert new audio, then pad to video duration
          args = [
            '-i', videoPath,
            '-i', audioPath,
            '-filter_complex',
            `[0:a]aselect='lt(t,${audioStartTime})',asetpts=N/SR/TB[before];` +
            `[1:a]volume=${volumeLevel}[new];` +
            `[0:a]aselect='gte(t,${endTime})',asetpts=N/SR/TB[after];` +
            `[before][new][after]concat=n=3:v=0:a=1,apad=whole_dur=${videoDuration}[aout]`,
            '-map', '0:v',
            '-map', '[aout]',
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-y',
            actualOutputPath
          ];
        } else if (mode === 'push') {
          // Push: Insert new audio and push existing audio backward
          // Get audio duration from audioPath
          const getAudioDuration = () => {
            return new Promise((resolve) => {
              const ffprobe = spawn(ffprobePath, [
                '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                audioPath
              ], { stdio: ['pipe', 'pipe', 'pipe'], windowsHide: true });

              let output = '';
              ffprobe.stdout.on('data', (data) => { output += data.toString('utf8'); });
              ffprobe.on('close', () => { resolve(parseFloat(output.trim()) || 0); });
            });
          };

          const audioDuration = await getAudioDuration();

          // Split original audio: before insertion point and after
          // Then concatenate: before + new audio + after (with delay)
          args = [
            '-i', videoPath,
            '-i', audioPath,
            '-filter_complex',
            `[0:a]aselect='lt(t,${audioStartTime})',asetpts=N/SR/TB[before];` +
            `[1:a]volume=${volumeLevel}[new];` +
            `[0:a]aselect='gte(t,${audioStartTime})',asetpts=N/SR/TB[after];` +
            `[before][new][after]concat=n=3:v=0:a=1[aout]`,
            '-map', '0:v',
            '-map', '[aout]',
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-y',
            actualOutputPath
          ];
        }
      } else {
        // Video has no audio - add audio as new track
        // Get video duration and pad audio to match
        const getVideoDuration = () => {
          return new Promise((resolve) => {
            const ffprobe = spawn(ffprobePath, [
              '-v', 'error',
              '-show_entries', 'format=duration',
              '-of', 'default=noprint_wrappers=1:nokey=1',
              videoPath
            ], { stdio: ['pipe', 'pipe', 'pipe'], windowsHide: true });

            let output = '';
            ffprobe.stdout.on('data', (data) => { output += data.toString('utf8'); });
            ffprobe.on('close', () => { resolve(parseFloat(output.trim()) || 0); });
          });
        };

        const videoDuration = await getVideoDuration();

        args = [
          '-i', videoPath,
          '-i', audioPath,
          '-filter_complex', `[1:a]volume=${volumeLevel},adelay=${startTimeMs}|${startTimeMs},apad=whole_dur=${videoDuration}[a1]`,
          '-map', '0:v',
          '-map', '[a1]',
          '-c:v', 'copy',
          '-c:a', 'aac',
          '-y',
          actualOutputPath
        ];
      }

      logInfo('ADD_AUDIO_COMMAND', 'FFmpeg command', { args: args.join(' ') });

      const ffmpeg = spawn(ffmpegPath, args, {
        stdio: ['pipe', 'pipe', 'pipe'],
        windowsHide: true
      });
      let errorOutput = '';

      ffmpeg.stderr.on('data', (data) => {
        const message = data.toString('utf8');
        errorOutput += message;
        mainWindow.webContents.send('ffmpeg-progress', message);
      });

      ffmpeg.on('close', (code) => {
        if (code === 0) {
          // If we used a temporary file, replace the original
          if (isSameFile) {
            try {
              fs.unlinkSync(videoPath); // Delete original
              fs.renameSync(actualOutputPath, outputPath); // Rename temp to original
              logInfo('ADD_AUDIO_SUCCESS', 'Audio addition completed (replaced original)', { outputPath });
              resolve({ success: true, outputPath });
            } catch (err) {
              logError('ADD_AUDIO_REPLACE_FAILED', 'Failed to replace original file', { error: err.message });
              reject(new Error(`파일 교체 실패: ${err.message}`));
            }
          } else {
            logInfo('ADD_AUDIO_SUCCESS', 'Audio addition completed', { outputPath });
            resolve({ success: true, outputPath });
          }
        } else {
          // Clean up temp file if it exists
          if (isSameFile && fs.existsSync(actualOutputPath)) {
            try {
              fs.unlinkSync(actualOutputPath);
            } catch (err) {
              // Ignore cleanup errors
            }
          }
          logError('ADD_AUDIO_FAILED', 'Audio addition failed', { error: errorOutput });
          reject(new Error(errorOutput || 'FFmpeg failed'));
        }
      });
    } catch (error) {
      logError('ADD_AUDIO_ERROR', 'Error during audio addition setup', { error: error.message });
      reject(error);
    }
  });
});

// Apply video filter
ipcMain.handle('apply-filter', async (event, options) => {
  let { inputPath, outputPath, filterName, filterParams } = options;

  // If outputPath is null, create temp file
  if (!outputPath) {
    const os = require('os');
    const tempDir = os.tmpdir();
    const timestamp = Date.now();
    const fileName = path.basename(inputPath, path.extname(inputPath));
    outputPath = path.join(tempDir, `${fileName}_${filterName}_${timestamp}.mp4`);
  }

  logInfo('FILTER_START', `Applying ${filterName} filter`, { inputPath, outputPath, filterParams });

  let filterString = '';
  switch (filterName) {
    case 'brightness':
      filterString = `eq=brightness=${filterParams.brightness}`;
      break;
    case 'contrast':
      filterString = `eq=contrast=${filterParams.contrast}`;
      break;
    case 'saturation':
      filterString = `eq=saturation=${filterParams.saturation}`;
      break;
    case 'blur':
      filterString = `gblur=sigma=${filterParams.sigma}`;
      break;
    case 'sharpen':
      filterString = `unsharp=5:5:${filterParams.amount}:5:5:0`;
      break;
    case 'rotate':
      filterString = `rotate=${filterParams.angle * Math.PI / 180}`;
      break;
    case 'speed':
      filterString = `setpts=${1 / filterParams.speed}*PTS`;
      break;
    default:
      logError('FILTER_FAILED', 'Unknown filter', { filterName });
      return Promise.reject(new Error('Unknown filter'));
  }

  return new Promise((resolve, reject) => {
    const args = [
      '-i', inputPath,
      '-vf', filterString,
      '-c:a', 'copy',
      '-y',
      outputPath
    ];

    const ffmpeg = spawn(ffmpegPath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });
    let errorOutput = '';

    ffmpeg.stderr.on('data', (data) => {
      const message = data.toString('utf8');
      errorOutput += message;
      mainWindow.webContents.send('ffmpeg-progress', message);
    });

    ffmpeg.on('close', (code) => {
      if (code === 0) {
        logInfo('FILTER_SUCCESS', `${filterName} filter applied`, { outputPath });
        resolve({ success: true, outputPath });
      } else {
        logError('FILTER_FAILED', `${filterName} filter failed`, { error: errorOutput });
        reject(new Error(errorOutput || 'FFmpeg failed'));
      }
    });
  });
});

// Merge multiple videos with transitions
ipcMain.handle('merge-videos', async (event, options) => {
  let { videoPaths, outputPath, transition, transitionDuration } = options;

  // If outputPath is null, create temp file
  if (!outputPath) {
    const os = require('os');
    const tempDir = os.tmpdir();
    const timestamp = Date.now();
    outputPath = path.join(tempDir, `merged_video_${timestamp}.mp4`);
  }

  logInfo('MERGE_START', 'Starting video merge', { videoCount: videoPaths.length, transition, outputPath });

  // Helper function to check if video has audio stream
  const hasAudioStream = (videoPath) => {
    return new Promise((resolve) => {
      const ffprobe = spawn(ffprobePath, [
        '-v', 'error',
        '-select_streams', 'a:0',
        '-show_entries', 'stream=codec_type',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        videoPath
      ], {
        stdio: ['pipe', 'pipe', 'pipe'],
        windowsHide: true
      });

      let output = '';
      ffprobe.stdout.on('data', (data) => {
        output += data.toString('utf8');
      });

      ffprobe.on('close', (code) => {
        const hasAudio = output.trim() === 'audio';
        resolve(hasAudio);
      });
    });
  };

  // Helper function to add silent audio to video
  const addSilentAudio = async (videoPath, duration) => {
    const os = require('os');
    const tempDir = os.tmpdir();
    const timestamp = Date.now();
    const fileName = path.basename(videoPath, path.extname(videoPath));
    const outputPathWithAudio = path.join(tempDir, `${fileName}_with_audio_${timestamp}.mp4`);

    return new Promise((resolve, reject) => {
      const args = [
        '-f', 'lavfi',
        '-i', `aevalsrc=random(0)*0.001|random(1)*0.001:d=${duration}:c=stereo:s=48000`,  // Very low noise (-60dB, inaudible) for waveform with log scale
        '-i', videoPath,
        '-c:v', 'copy',
        '-c:a', 'aac',
        '-b:a', '192k',   // HIGH BITRATE for silent audio (important!)
        '-ar', '48000',   // Sample rate (48000Hz for higher quality)
        '-ac', '2',       // Stereo channels
        '-map', '1:v',
        '-map', '0:a',
        '-movflags', '+faststart',  // Write moov atom at start for better compatibility
        '-y',
        outputPathWithAudio
      ];

      logInfo('ADD_SILENT_AUDIO', 'Adding silent audio for merge with 192k bitrate', { videoPath, outputPathWithAudio, duration });

      const ffmpeg = spawn(ffmpegPath, args, {
        stdio: ['pipe', 'pipe', 'pipe'],
        windowsHide: true
      });

      let errorOutput = '';
      ffmpeg.stderr.on('data', (data) => {
        errorOutput += data.toString('utf8');
      });

      ffmpeg.on('close', (code) => {
        if (code === 0) {
          logInfo('ADD_SILENT_AUDIO_SUCCESS', 'Silent audio added', { outputPathWithAudio });
          resolve(outputPathWithAudio);
        } else {
          logError('ADD_SILENT_AUDIO_FAILED', 'Failed to add silent audio', { error: errorOutput });
          reject(new Error(errorOutput || 'Failed to add silent audio'));
        }
      });

      ffmpeg.on('error', (err) => {
        logError('ADD_SILENT_AUDIO_ERROR', 'FFmpeg spawn error', { error: err.message });
        reject(new Error(`FFmpeg error: ${err.message}`));
      });
    });
  };

  // Helper function to get video duration
  const getVideoDuration = (videoPath) => {
    return new Promise((resolve, reject) => {
      const ffprobe = spawn(ffprobePath, [
        '-v', 'quiet',
        '-print_format', 'json',
        '-show_format',
        '-show_streams',
        videoPath
      ], {
        stdio: ['pipe', 'pipe', 'pipe'],
        windowsHide: true
      });

      let output = '';
      let errorOutput = '';

      ffprobe.stdout.on('data', (data) => {
        output += data.toString('utf8');
      });

      ffprobe.stderr.on('data', (data) => {
        errorOutput += data.toString('utf8');
      });

      ffprobe.on('close', (code) => {
        if (code === 0 && output) {
          try {
            const info = JSON.parse(output);
            const duration = parseFloat(info.format.duration);
            if (isNaN(duration) || duration <= 0) {
              logError('GET_DURATION_INVALID', 'Invalid duration value', { videoPath, duration, output });
              reject(new Error(`Invalid duration: ${duration}`));
            } else {
              resolve(duration);
            }
          } catch (err) {
            logError('GET_DURATION_PARSE_ERROR', 'Failed to parse ffprobe output', { error: err.message, output });
            reject(new Error('Failed to parse duration'));
          }
        } else {
          logError('GET_DURATION_FAILED', 'FFprobe failed', { code, errorOutput });
          reject(new Error('Failed to get video duration'));
        }
      });
    });
  };

  return new Promise(async (resolve, reject) => {
    try {
      // Check all videos for audio and add silent audio if missing
      const processedVideoPaths = [];
      const videoHasAudio = [];  // Track which videos have audio after processing

      for (let i = 0; i < videoPaths.length; i++) {
        const videoPath = videoPaths[i];
        const hasAudio = await hasAudioStream(videoPath);

        if (!hasAudio) {
          logInfo('MERGE_NO_AUDIO', 'Video has no audio, adding silent track', { videoPath, index: i });
          try {
            const duration = await getVideoDuration(videoPath);
            const videoWithAudio = await addSilentAudio(videoPath, duration);

            // Verify audio was actually added
            const hasAudioAfter = await hasAudioStream(videoWithAudio);
            if (hasAudioAfter) {
              processedVideoPaths.push(videoWithAudio);
              videoHasAudio.push(true);
              logInfo('MERGE_AUDIO_ADDED', 'Silent audio added successfully', { index: i, newPath: videoWithAudio });
            } else {
              logError('MERGE_AUDIO_VERIFY_FAILED', 'Audio stream not found after addition', { videoPath, index: i });
              throw new Error(`Failed to add audio to video ${i + 1}. Please try again.`);
            }
          } catch (err) {
            logError('MERGE_AUDIO_ADD_ERROR', 'Failed to add silent audio', { error: err.message, index: i });
            throw new Error(`Failed to add audio to video ${i + 1}: ${err.message}`);
          }
        } else {
          logInfo('MERGE_HAS_AUDIO', 'Video already has audio', { videoPath, index: i });
          processedVideoPaths.push(videoPath);
          videoHasAudio.push(true);
        }
      }

      // Use processed video paths for merge
      videoPaths = processedVideoPaths;

      let filterComplex = '';
      let inputs = [];

      // Add all input files
      videoPaths.forEach(path => {
        inputs.push('-i', path);
      });

      // Parse transition type and effect
      let transitionType = transition;
      let transitionEffect = 'fade';

      if (transition.startsWith('xfade-')) {
        transitionType = 'xfade';
        transitionEffect = transition.substring(6); // Extract effect name after 'xfade-'
      }

      // Build filter chain based on transition type
      if (transitionType === 'xfade') {
        // Get durations of all videos
        const durations = await Promise.all(videoPaths.map(path => getVideoDuration(path)));

        // Normalize all videos first (all videos guaranteed to have audio at this point)
        for (let i = 0; i < videoPaths.length; i++) {
          filterComplex += `[${i}:v]scale=1920:1080:force_original_aspect_ratio=decrease,pad=1920:1080:(ow-iw)/2:(oh-ih)/2,setsar=1[v${i}];`;
          filterComplex += `[${i}:a]aresample=48000,aformat=sample_rates=48000:channel_layouts=stereo[a${i}];`; // Resample to 48000Hz stereo (higher quality)
        }

        // Apply xfade transitions with correct offsets and specified effect
        let currentLabel = 'v0';
        let offset = durations[0] - transitionDuration;
        for (let i = 1; i < videoPaths.length; i++) {
          const nextLabel = i === videoPaths.length - 1 ? 'outv' : `v${i}x`;
          filterComplex += `[${currentLabel}][v${i}]xfade=transition=${transitionEffect}:duration=${transitionDuration}:offset=${offset.toFixed(2)}[${nextLabel}];`;
          currentLabel = nextLabel;
          if (i < videoPaths.length - 1) {
            offset += durations[i] - transitionDuration;
          }
        }

        // Concatenate audio separately (simple concat, no crossfade for audio)
        filterComplex += videoPaths.map((_, i) => `[a${i}]`).join('') + `concat=n=${videoPaths.length}:v=0:a=1[outa]`;
      } else if (transitionType === 'fade') {
        // Simple fade transition (fade out first video, fade in second video)
        const durations = await Promise.all(videoPaths.map(path => getVideoDuration(path)));

        // Normalize all videos first
        for (let i = 0; i < videoPaths.length; i++) {
          filterComplex += `[${i}:v]scale=1920:1080:force_original_aspect_ratio=decrease,pad=1920:1080:(ow-iw)/2:(oh-ih)/2,setsar=1[v${i}];`;
          filterComplex += `[${i}:a]aresample=48000,aformat=sample_rates=48000:channel_layouts=stereo[a${i}];`;
        }

        // Apply fade out/in transitions to each video
        for (let i = 0; i < videoPaths.length; i++) {
          if (i === 0) {
            // First video: only fade out at the end
            const fadeStartTime = durations[i] - transitionDuration;
            filterComplex += `[v${i}]fade=t=out:st=${fadeStartTime.toFixed(2)}:d=${transitionDuration}[v${i}f];`;
          } else if (i === videoPaths.length - 1) {
            // Last video: only fade in at the start
            filterComplex += `[v${i}]fade=t=in:st=0:d=${transitionDuration}[v${i}f];`;
          } else {
            // Middle videos: fade in at start and fade out at end
            const fadeStartTime = durations[i] - transitionDuration;
            filterComplex += `[v${i}]fade=t=in:st=0:d=${transitionDuration},fade=t=out:st=${fadeStartTime.toFixed(2)}:d=${transitionDuration}[v${i}f];`;
          }
        }

        // Concatenate faded videos
        filterComplex += videoPaths.map((_, i) => `[v${i}f]`).join('') + `concat=n=${videoPaths.length}:v=1:a=0[outv];`;

        // Concatenate audio separately
        filterComplex += videoPaths.map((_, i) => `[a${i}]`).join('') + `concat=n=${videoPaths.length}:v=0:a=1[outa]`;
      } else {
        // Simple concatenation - normalize videos and concat with audio (all videos guaranteed to have audio)
        for (let i = 0; i < videoPaths.length; i++) {
          filterComplex += `[${i}:v]scale=1920:1080:force_original_aspect_ratio=decrease,pad=1920:1080:(ow-iw)/2:(oh-ih)/2,setsar=1[v${i}];`;
          filterComplex += `[${i}:a]aresample=48000,aformat=sample_rates=48000:channel_layouts=stereo[a${i}];`; // Resample to 48000Hz stereo (higher quality)
        }
        // Concat both video and audio
        filterComplex += videoPaths.map((_, i) => `[v${i}][a${i}]`).join('') + `concat=n=${videoPaths.length}:v=1:a=1[outv][outa]`;
      }

      const args = [
        ...inputs,
        '-filter_complex', filterComplex,
        '-map', '[outv]',
        '-map', '[outa]',  // Map audio output
        '-c:v', 'libx264',
        '-c:a', 'aac',      // Encode audio as AAC
        '-b:a', '192k',     // Audio bitrate (important for quality)
        '-ar', '48000',     // Sample rate (48000Hz for higher quality)
        '-ac', '2',         // Stereo channels
        '-preset', 'medium',
        '-crf', '23',
        '-movflags', '+faststart',  // Write moov atom at start
        '-y',
        outputPath
      ];

      logInfo('MERGE_FFMPEG_CMD', 'FFmpeg merge command', { filterComplex });

      const ffmpeg = spawn(ffmpegPath, args, {
        stdio: ['pipe', 'pipe', 'pipe'],
        windowsHide: true
      });
      let errorOutput = '';

      ffmpeg.stderr.on('data', (data) => {
        const message = data.toString('utf8');
        errorOutput += message;
        mainWindow.webContents.send('ffmpeg-progress', message);
      });

      ffmpeg.on('close', (code) => {
        if (code === 0) {
          logInfo('MERGE_SUCCESS', 'Video merge completed', { outputPath });
          resolve({ success: true, outputPath });
        } else {
          logError('MERGE_FAILED', 'Video merge failed', { error: errorOutput });
          reject(new Error(errorOutput || 'FFmpeg failed'));
        }
      });
    } catch (error) {
      logError('MERGE_ERROR', 'Error during merge setup', { error: error.message });
      reject(error);
    }
  });
});

// Merge audio files (simple concatenation only)
ipcMain.handle('merge-audios', async (event, options) => {
  const { audioPaths, outputPath } = options;

  logInfo('MERGE_AUDIO_START', 'Starting audio merge (concat)', { audioCount: audioPaths.length });

  return new Promise(async (resolve, reject) => {
    try {
      // If outputPath is null, create temp file
      let actualOutputPath = outputPath;
      if (!actualOutputPath) {
        const os = require('os');
        const tempDir = os.tmpdir();
        const timestamp = Date.now();
        actualOutputPath = path.join(tempDir, `merged_audio_${timestamp}.mp3`);
        logInfo('MERGE_AUDIO_TEMP', 'Creating temp file', { actualOutputPath });
      }
      actualOutputPath = actualOutputPath.replace(/\\/g, '/');
      let inputs = [];

      // Add all input files
      audioPaths.forEach(path => {
        inputs.push('-i', path);
      });

      // Simple concatenation using concat filter
      const filterComplex = audioPaths.map((_, i) => `[${i}:a]`).join('') + `concat=n=${audioPaths.length}:v=0:a=1[outa]`;

      const args = [
        ...inputs,
        '-filter_complex', filterComplex,
        '-map', '[outa]',
        '-c:a', 'libmp3lame',
        '-q:a', '2',
        '-y',
        actualOutputPath
      ];

      logInfo('MERGE_AUDIO_FFMPEG_CMD', 'FFmpeg audio merge command', { args });

      const ffmpeg = spawn(ffmpegPath, args, {
        stdio: ['pipe', 'pipe', 'pipe'],
        windowsHide: true
      });
      let errorOutput = '';

      ffmpeg.stderr.on('data', (data) => {
        const message = data.toString('utf8');
        errorOutput += message;
        mainWindow.webContents.send('ffmpeg-progress', message);
      });

      ffmpeg.on('close', (code) => {
        if (code === 0) {
          logInfo('MERGE_AUDIO_SUCCESS', 'Audio merge completed', { outputPath: actualOutputPath });
          resolve({ success: true, outputPath: actualOutputPath });
        } else {
          logError('MERGE_AUDIO_FAILED', 'Audio merge failed', { error: errorOutput });
          reject(new Error(errorOutput || 'FFmpeg failed'));
        }
      });
    } catch (error) {
      logError('MERGE_AUDIO_ERROR', 'Error during audio merge setup', { error: error.message });
      reject(error);
    }
  });
});

// Add text/subtitle overlay
ipcMain.handle('add-text', async (event, options) => {
  let { inputPath, outputPath, text, fontSize, fontColor, fontFamily, fontStyle, position, startTime, duration } = options;

  // If outputPath is null, create temp file
  if (!outputPath) {
    const os = require('os');
    const tempDir = os.tmpdir();
    const timestamp = Date.now();
    const fileName = path.basename(inputPath, path.extname(inputPath));
    outputPath = path.join(tempDir, `${fileName}_text_${timestamp}.mp4`);
  }

  logInfo('ADD_TEXT_START', 'Adding text overlay', { text, fontSize, outputPath });

  return new Promise(async (resolve, reject) => {
    try {
      const x = position.x || '(w-text_w)/2';
      const y = position.y || '(h-text_h)/2';

      // Determine font name with style
      let fontName = fontFamily || 'Malgun Gothic';
      const style = fontStyle || 'regular';

      if (style === 'bold') {
        fontName += ' Bold';
      } else if (style === 'italic') {
        fontName += ' Italic';
      } else if (style === 'bold-italic') {
        fontName += ' Bold Italic';
      }

      // If startTime and duration are specified, use optimized 3-segment approach
      if (startTime !== undefined && duration !== undefined && startTime > 0) {
        const endTime = startTime + duration;
        const os = require('os');
        const tempDir = os.tmpdir();
        const timestamp = Date.now();

        // Get video duration
        const videoInfo = await getVideoInfo(inputPath);
        const totalDuration = parseFloat(videoInfo.format.duration);

        // Only optimize if text is not covering the entire video
        if (endTime < totalDuration - 0.1) {
          logInfo('ADD_TEXT_OPTIMIZED', 'Using optimized 3-segment approach', { startTime, endTime, totalDuration });

          // Temp file paths
          const segment1Path = path.join(tempDir, `segment1_${timestamp}.mp4`);
          const segment2Path = path.join(tempDir, `segment2_${timestamp}.mp4`);
          const segment3Path = path.join(tempDir, `segment3_${timestamp}.mp4`);
          const concatListPath = path.join(tempDir, `concat_${timestamp}.txt`);

          // Step 1: Extract segment before text (copy, no re-encode)
          await new Promise((res, rej) => {
            const args1 = [
              '-i', inputPath,
              '-t', startTime.toString(),
              '-c', 'copy',
              '-y',
              segment1Path
            ];

            const ffmpeg1 = spawn(ffmpegPath, args1, { stdio: ['pipe', 'pipe', 'pipe'], windowsHide: true });
            let errorOutput = '';

            ffmpeg1.stderr.on('data', (data) => {
              errorOutput += data.toString('utf8');
            });

            ffmpeg1.on('close', (code) => {
              if (code === 0) res();
              else rej(new Error('Segment 1 failed: ' + errorOutput));
            });
          });

          // Step 2: Extract segment with text and apply text overlay (encode)
          await new Promise((res, rej) => {
            const filterString = `drawtext=text='${text}':font='${fontName}':fontsize=${fontSize}:fontcolor=${fontColor}:x=${x}:y=${y}`;
            const args2 = [
              '-i', inputPath,
              '-ss', startTime.toString(),
              '-t', duration.toString(),
              '-vf', filterString,
              '-c:a', 'copy',
              '-y',
              segment2Path
            ];

            const ffmpeg2 = spawn(ffmpegPath, args2, { stdio: ['pipe', 'pipe', 'pipe'], windowsHide: true });
            let errorOutput = '';

            ffmpeg2.stderr.on('data', (data) => {
              const message = data.toString('utf8');
              errorOutput += message;
              mainWindow.webContents.send('ffmpeg-progress', message);
            });

            ffmpeg2.on('close', (code) => {
              if (code === 0) res();
              else rej(new Error('Segment 2 failed: ' + errorOutput));
            });
          });

          // Step 3: Extract segment after text (copy, no re-encode)
          await new Promise((res, rej) => {
            const args3 = [
              '-i', inputPath,
              '-ss', endTime.toString(),
              '-c', 'copy',
              '-y',
              segment3Path
            ];

            const ffmpeg3 = spawn(ffmpegPath, args3, { stdio: ['pipe', 'pipe', 'pipe'], windowsHide: true });
            let errorOutput = '';

            ffmpeg3.stderr.on('data', (data) => {
              errorOutput += data.toString('utf8');
            });

            ffmpeg3.on('close', (code) => {
              if (code === 0) res();
              else rej(new Error('Segment 3 failed: ' + errorOutput));
            });
          });

          // Step 4: Concatenate segments
          const fs = require('fs');
          const concatContent = `file '${segment1Path.replace(/\\/g, '/')}'\nfile '${segment2Path.replace(/\\/g, '/')}'\nfile '${segment3Path.replace(/\\/g, '/')}'`;
          fs.writeFileSync(concatListPath, concatContent);

          await new Promise((res, rej) => {
            const args4 = [
              '-f', 'concat',
              '-safe', '0',
              '-i', concatListPath,
              '-c', 'copy',
              '-y',
              outputPath
            ];

            const ffmpeg4 = spawn(ffmpegPath, args4, { stdio: ['pipe', 'pipe', 'pipe'], windowsHide: true });
            let errorOutput = '';

            ffmpeg4.stderr.on('data', (data) => {
              errorOutput += data.toString('utf8');
            });

            ffmpeg4.on('close', (code) => {
              // Cleanup temp files
              try {
                fs.unlinkSync(segment1Path);
                fs.unlinkSync(segment2Path);
                fs.unlinkSync(segment3Path);
                fs.unlinkSync(concatListPath);
              } catch (e) {
                logError('CLEANUP_FAILED', 'Failed to cleanup temp files', { error: e.message });
              }

              if (code === 0) {
                logInfo('ADD_TEXT_SUCCESS', 'Text overlay added (optimized)', { outputPath });
                res();
              } else {
                rej(new Error('Concatenation failed: ' + errorOutput));
              }
            });
          });

          resolve({ success: true, outputPath });
          return;
        }
      }

      // Fallback to standard approach (process entire video)
      logInfo('ADD_TEXT_STANDARD', 'Using standard full-video approach');

      let filterString = `drawtext=text='${text}':font='${fontName}':fontsize=${fontSize}:fontcolor=${fontColor}:x=${x}:y=${y}`;

      if (startTime !== undefined && duration !== undefined) {
        filterString += `:enable='between(t,${startTime},${startTime + duration})'`;
      }

      const args = [
        '-i', inputPath,
        '-vf', filterString,
        '-c:a', 'copy',
        '-y',
        outputPath
      ];

      const ffmpeg = spawn(ffmpegPath, args, {
        stdio: ['pipe', 'pipe', 'pipe'],
        windowsHide: true
      });
      let errorOutput = '';

      ffmpeg.stderr.on('data', (data) => {
        const message = data.toString('utf8');
        errorOutput += message;
        mainWindow.webContents.send('ffmpeg-progress', message);
      });

      ffmpeg.on('close', (code) => {
        if (code === 0) {
          logInfo('ADD_TEXT_SUCCESS', 'Text overlay added', { outputPath });
          resolve({ success: true, outputPath });
        } else {
          logError('ADD_TEXT_FAILED', 'Text overlay failed', { error: errorOutput });
          reject(new Error(errorOutput || 'FFmpeg failed'));
        }
      });
    } catch (error) {
      logError('ADD_TEXT_ERROR', 'Unexpected error in add-text', { error: error.message });
      reject(error);
    }
  });
});

// Extract audio from video
ipcMain.handle('extract-audio', async (event, options) => {
  let { videoPath, outputPath } = options;

  // If outputPath is null, undefined, or the string "null", create temp file
  if (!outputPath || outputPath === 'null' || outputPath === 'undefined') {
    const timestamp = Date.now();
    const basename = path.basename(videoPath, path.extname(videoPath));
    outputPath = path.join(os.tmpdir(), `${basename}_extracted_${timestamp}.mp3`);
    logInfo('EXTRACT_AUDIO_TEMP', 'Creating temp file', { actualOutputPath: outputPath });
  }

  logInfo('EXTRACT_AUDIO_START', 'Extracting audio from video', { videoPath, outputPath });

  return new Promise((resolve, reject) => {
    const args = [
      '-i', videoPath,
      '-vn',
      '-acodec', 'mp3',
      '-ab', '192k',
      '-y',
      outputPath
    ];

    const ffmpeg = spawn(ffmpegPath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });
    let errorOutput = '';

    ffmpeg.stderr.on('data', (data) => {
      const message = data.toString('utf8');
      errorOutput += message;
      mainWindow.webContents.send('ffmpeg-progress', message);
    });

    ffmpeg.on('close', (code) => {
      if (code === 0) {
        logInfo('EXTRACT_AUDIO_SUCCESS', 'Audio extraction completed', { outputPath });
        resolve({ success: true, outputPath });
      } else {
        logError('EXTRACT_AUDIO_FAILED', 'Audio extraction failed', { error: errorOutput });
        reject(new Error(errorOutput || 'FFmpeg failed'));
      }
    });

    ffmpeg.on('error', (err) => {
      logError('EXTRACT_AUDIO_FAILED', 'FFmpeg spawn error', { error: err.message });
      reject(new Error(`FFmpeg error: ${err.message}`));
    });
  });
});

// Adjust audio speed
ipcMain.handle('adjust-audio-speed', async (event, options) => {
  let { inputPath, outputPath, speed } = options;

  // If outputPath is null, create temp file
  if (!outputPath) {
    const os = require('os');
    const tempDir = os.tmpdir();
    const timestamp = Date.now();
    const fileName = path.basename(inputPath, path.extname(inputPath));
    outputPath = path.join(tempDir, `${fileName}_speed_${speed}x_${timestamp}.mp3`);
  }

  logInfo('ADJUST_AUDIO_SPEED_START', 'Adjusting audio speed', { inputPath, speed, outputPath });

  return new Promise((resolve, reject) => {
    // FFmpeg atempo filter: values from 0.5 to 100.0 are supported
    // For speeds outside this range, we need to chain multiple atempo filters
    let filterString = '';

    if (speed >= 0.5 && speed <= 2.0) {
      // Single atempo filter
      filterString = `atempo=${speed}`;
    } else if (speed < 0.5) {
      // Chain multiple atempo filters for very slow speeds
      // e.g., 0.25x = atempo=0.5,atempo=0.5
      let currentSpeed = speed;
      let filters = [];
      while (currentSpeed < 0.5) {
        filters.push('atempo=0.5');
        currentSpeed *= 2;
      }
      if (currentSpeed < 1.0) {
        filters.push(`atempo=${currentSpeed}`);
      }
      filterString = filters.join(',');
    } else {
      // Chain multiple atempo filters for very fast speeds
      // e.g., 4.0x = atempo=2.0,atempo=2.0
      let currentSpeed = speed;
      let filters = [];
      while (currentSpeed > 2.0) {
        filters.push('atempo=2.0');
        currentSpeed /= 2;
      }
      if (currentSpeed > 1.0) {
        filters.push(`atempo=${currentSpeed}`);
      }
      filterString = filters.join(',');
    }

    const args = [
      '-i', inputPath,
      '-af', filterString,
      '-y',
      outputPath
    ];

    const ffmpeg = spawn(ffmpegPath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });
    let errorOutput = '';

    ffmpeg.stderr.on('data', (data) => {
      const message = data.toString('utf8');
      errorOutput += message;
      mainWindow.webContents.send('ffmpeg-progress', message);
    });

    ffmpeg.on('close', (code) => {
      if (code === 0) {
        logInfo('ADJUST_AUDIO_SPEED_SUCCESS', 'Audio speed adjusted', { outputPath, speed });
        resolve({ success: true, outputPath });
      } else {
        logError('ADJUST_AUDIO_SPEED_FAILED', 'Audio speed adjustment failed', { error: errorOutput });
        reject(new Error(errorOutput || 'FFmpeg failed'));
      }
    });

    ffmpeg.on('error', (err) => {
      logError('ADJUST_AUDIO_SPEED_FAILED', 'FFmpeg spawn error', { error: err.message });
      reject(new Error(`FFmpeg error: ${err.message}`));
    });
  });
});

// Generate silence file
ipcMain.handle('generate-silence-file', async (event, options) => {
  const { duration } = options;

  logInfo('GENERATE_SILENCE_START', 'Generating silence file', { duration });

  // Create temporary file path
  const os = require('os');
  const tempDir = os.tmpdir();
  const timestamp = Date.now();
  const outputPath = path.join(tempDir, `silence_${timestamp}_${duration}s.mp3`);

  return new Promise((resolve, reject) => {
    const args = [
      '-f', 'lavfi',
      '-i', `anullsrc=r=44100:cl=stereo:d=${duration}`,
      '-acodec', 'libmp3lame',
      '-ab', '192k',
      '-y',
      outputPath
    ];

    logInfo('GENERATE_SILENCE', 'Running FFmpeg', { ffmpegPath, args });

    const ffmpeg = spawn(ffmpegPath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });
    let errorOutput = '';

    ffmpeg.stderr.on('data', (data) => {
      const message = data.toString('utf8');
      errorOutput += message;
      mainWindow.webContents.send('ffmpeg-progress', message);
    });

    ffmpeg.on('close', (code) => {
      if (code === 0) {
        logInfo('GENERATE_SILENCE_SUCCESS', 'Silence file generated', { outputPath, duration });
        resolve({ success: true, outputPath });
      } else {
        logError('GENERATE_SILENCE_FAILED', 'Silence generation failed', { error: errorOutput });
        reject(new Error(errorOutput || 'FFmpeg failed'));
      }
    });

    ffmpeg.on('error', (err) => {
      logError('GENERATE_SILENCE_FAILED', 'FFmpeg spawn error', { error: err.message });
      reject(new Error(`FFmpeg error: ${err.message}`));
    });
  });
});

// Trim audio file (for MP3, WAV, etc.)
ipcMain.handle('trim-audio-file', async (event, options) => {
  const { inputPath, outputPath, startTime, endTime } = options;

  logInfo('TRIM_AUDIO_FILE_START', 'Starting audio file trim', { inputPath, startTime, endTime });

  // If outputPath is null, create temp file
  let actualOutputPath;
  let isSameFile = false;

  if (!outputPath) {
    const os = require('os');
    const tempDir = os.tmpdir();
    const timestamp = Date.now();
    const fileName = path.basename(inputPath, path.extname(inputPath));
    actualOutputPath = path.join(tempDir, `${fileName}_trimmed_${timestamp}.mp3`);
    logInfo('TRIM_AUDIO_FILE_TEMP', 'Creating temp file', { actualOutputPath });
  } else {
    // Check if input and output are the same file
    isSameFile = path.resolve(inputPath) === path.resolve(outputPath);

    // If same file, create temp file with proper extension
    if (isSameFile) {
      const ext = path.extname(outputPath);
      const base = outputPath.slice(0, -ext.length);
      actualOutputPath = `${base}_temp_${Date.now()}${ext}`;
      logInfo('TRIM_AUDIO_FILE_SAME_FILE', 'Same file detected, using temp file', { actualOutputPath });
    } else {
      actualOutputPath = outputPath;
    }
  }

  const duration = endTime - startTime;

  return new Promise((resolve, reject) => {
    const args = [
      '-i', inputPath,
      '-ss', startTime.toString(),
      '-t', duration.toString(),
      '-acodec', 'copy',  // Copy codec for lossless trim
      '-y',
      actualOutputPath
    ];

    const ffmpeg = spawn(ffmpegPath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });
    let errorOutput = '';

    ffmpeg.stderr.on('data', (data) => {
      const message = data.toString('utf8');
      errorOutput += message;
      mainWindow.webContents.send('ffmpeg-progress', message);
    });

    ffmpeg.on('close', (code) => {
      if (code === 0) {
        let finalOutputPath = actualOutputPath;

        // If we used a temp file for same file replacement, replace the original
        if (isSameFile) {
          try {
            if (fs.existsSync(outputPath)) {
              fs.unlinkSync(outputPath);
            }
            fs.renameSync(actualOutputPath, outputPath);
            finalOutputPath = outputPath;
            logInfo('TRIM_AUDIO_FILE_SUCCESS', 'Audio file trim completed, temp file replaced', { outputPath });
          } catch (err) {
            logError('TRIM_AUDIO_FILE_REPLACE_FAILED', 'Failed to replace original file', { error: err.message });
            reject(new Error(`Failed to replace file: ${err.message}`));
            return;
          }
        } else {
          logInfo('TRIM_AUDIO_FILE_SUCCESS', 'Audio file trim completed', { outputPath: actualOutputPath });
        }
        resolve({ success: true, outputPath: finalOutputPath });
      } else {
        // Clean up temp file if it exists
        if (isSameFile && fs.existsSync(actualOutputPath)) {
          try {
            fs.unlinkSync(actualOutputPath);
          } catch (err) {
            logError('TRIM_AUDIO_FILE_CLEANUP_FAILED', 'Failed to clean up temp file', { error: err.message });
          }
        }
        logError('TRIM_AUDIO_FILE_FAILED', 'Audio file trim failed', { error: errorOutput });
        reject(new Error(errorOutput || 'FFmpeg failed'));
      }
    });

    ffmpeg.on('error', (err) => {
      // Clean up temp file if it exists
      if (isSameFile && fs.existsSync(actualOutputPath)) {
        try {
          fs.unlinkSync(actualOutputPath);
        } catch (cleanupErr) {
          logError('TRIM_AUDIO_FILE_CLEANUP_FAILED', 'Failed to clean up temp file', { error: cleanupErr.message });
        }
      }
      logError('TRIM_AUDIO_FILE_FAILED', 'FFmpeg spawn error', { error: err.message });
      reject(new Error(`FFmpeg error: ${err.message}`));
    });
  });
});

// Copy audio file
ipcMain.handle('copy-audio-file', async (event, options) => {
  const { inputPath, outputPath } = options;

  logInfo('COPY_AUDIO_FILE_START', 'Starting audio file copy', { inputPath, outputPath });

  return new Promise((resolve, reject) => {
    try {
      // Check if input file exists
      if (!fs.existsSync(inputPath)) {
        const error = 'Input file does not exist';
        logError('COPY_AUDIO_FILE_FAILED', error, { inputPath });
        reject(new Error(error));
        return;
      }

      // Copy file
      fs.copyFileSync(inputPath, outputPath);

      // Check if input file is in temp directory and delete it
      const os = require('os');
      const tempDir = os.tmpdir();
      const inputDir = path.dirname(inputPath);

      if (inputDir === tempDir) {
        try {
          fs.unlinkSync(inputPath);
          logInfo('COPY_AUDIO_FILE_CLEANUP', 'Temp file deleted after export', { inputPath });
        } catch (cleanupError) {
          logError('COPY_AUDIO_FILE_CLEANUP_FAILED', 'Failed to delete temp file', {
            inputPath,
            error: cleanupError.message
          });
          // Don't fail the operation if cleanup fails
        }
      }

      logInfo('COPY_AUDIO_FILE_SUCCESS', 'Audio file copied successfully', { outputPath });
      resolve({ success: true, outputPath });
    } catch (error) {
      logError('COPY_AUDIO_FILE_ERROR', 'Error copying audio file', { error: error.message });
      reject(new Error(`Copy error: ${error.message}`));
    }
  });
});

// Open file with system default application
ipcMain.handle('open-path', async (event, filePath) => {
  const { shell } = require('electron');
  logInfo('OPEN_PATH', 'Opening file with system default application', { filePath });

  try {
    const result = await shell.openPath(filePath);
    if (result) {
      logError('OPEN_PATH_FAILED', 'Failed to open file', { error: result });
      throw new Error(result);
    }
    logInfo('OPEN_PATH_SUCCESS', 'File opened successfully', { filePath });
    return { success: true };
  } catch (error) {
    logError('OPEN_PATH_ERROR', 'Error opening file', { error: error.message });
    throw error;
  }
});

// Delete temp file
ipcMain.handle('delete-temp-file', async (event, filePath) => {
  logInfo('DELETE_TEMP_FILE_START', 'Deleting temp file', { filePath });

  return new Promise((resolve, reject) => {
    try {
      // Check if file is in temp directory
      const os = require('os');
      const tempDir = os.tmpdir();
      const fileDir = path.dirname(filePath);

      if (fileDir !== tempDir) {
        logInfo('DELETE_TEMP_FILE_SKIP', 'File is not in temp directory, skipping', { filePath, fileDir, tempDir });
        resolve({ success: true, skipped: true });
        return;
      }

      // Check if file exists
      if (!fs.existsSync(filePath)) {
        logInfo('DELETE_TEMP_FILE_NOT_FOUND', 'File does not exist', { filePath });
        resolve({ success: true, notFound: true });
        return;
      }

      // Delete file
      fs.unlinkSync(filePath);
      logInfo('DELETE_TEMP_FILE_SUCCESS', 'Temp file deleted successfully', { filePath });
      resolve({ success: true });
    } catch (error) {
      logError('DELETE_TEMP_FILE_ERROR', 'Error deleting temp file', { filePath, error: error.message });
      // Don't reject - temp file cleanup failures shouldn't break the app
      resolve({ success: false, error: error.message });
    }
  });
});

// Ensure video has audio track (add silent audio if missing)
ipcMain.handle('ensure-video-has-audio', async (event, videoPath) => {
  logInfo('ENSURE_AUDIO_START', 'Checking video for audio track', { videoPath });

  // Check if video has audio stream
  const hasAudio = await new Promise((resolve) => {
    const ffprobe = spawn(ffprobePath, [
      '-v', 'error',
      '-select_streams', 'a:0',
      '-show_entries', 'stream=codec_type',
      '-of', 'default=noprint_wrappers=1:nokey=1',
      videoPath
    ], {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });

    let output = '';
    ffprobe.stdout.on('data', (data) => {
      output += data.toString('utf8');
    });

    ffprobe.on('close', (code) => {
      const hasAudio = output.trim() === 'audio';
      resolve(hasAudio);
    });
  });

  // If video has audio, return original path
  if (hasAudio) {
    logInfo('ENSURE_AUDIO_EXISTS', 'Video already has audio', { videoPath });
    return { hasAudio: true, videoPath };
  }

  // Get video duration
  const duration = await new Promise((resolve, reject) => {
    const ffprobe = spawn(ffprobePath, [
      '-v', 'error',
      '-show_entries', 'format=duration',
      '-of', 'default=noprint_wrappers=1:nokey=1',
      videoPath
    ], {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });

    let output = '';
    ffprobe.stdout.on('data', (data) => {
      output += data.toString('utf8');
    });

    ffprobe.on('close', (code) => {
      if (code === 0) {
        resolve(parseFloat(output.trim()));
      } else {
        reject(new Error('Failed to get video duration'));
      }
    });
  });

  // Create temp file with silent audio
  const os = require('os');
  const tempDir = os.tmpdir();
  const timestamp = Date.now();
  const fileName = path.basename(videoPath, path.extname(videoPath));
  const outputPath = path.join(tempDir, `${fileName}_with_audio_${timestamp}.mp4`);

  return new Promise((resolve, reject) => {
    const args = [
      '-f', 'lavfi',
      '-i', `aevalsrc=random(0)*0.001|random(1)*0.001:d=${duration}:c=stereo:s=48000`,  // Very low noise (-60dB, inaudible) for waveform with log scale
      '-i', videoPath,
      '-c:v', 'copy',
      '-c:a', 'aac',
      '-b:a', '192k',   // HIGH BITRATE for silent audio (important!)
      '-ar', '48000',   // Sample rate (48000Hz for higher quality)
      '-ac', '2',       // Stereo channels
      '-map', '1:v',  // Map video from second input (videoPath)
      '-map', '0:a',  // Map audio from first input (low noise)
      '-movflags', '+faststart',  // Write moov atom at start for better compatibility
      '-y',
      outputPath
    ];

    logInfo('ENSURE_AUDIO_FFMPEG', 'Adding silent audio track with 192k bitrate', { duration, videoPath, outputPath });

    const ffmpeg = spawn(ffmpegPath, args, {
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true
    });

    let errorOutput = '';

    ffmpeg.stderr.on('data', (data) => {
      errorOutput += data.toString('utf8');
    });

    ffmpeg.on('close', (code) => {
      if (code === 0) {
        logInfo('ENSURE_AUDIO_SUCCESS', 'Silent audio added successfully', { outputPath });
        resolve({ hasAudio: false, videoPath: outputPath, addedAudio: true });
      } else {
        logError('ENSURE_AUDIO_FAILED', 'Failed to add silent audio', { error: errorOutput });
        reject(new Error(errorOutput || 'FFmpeg failed'));
      }
    });

    ffmpeg.on('error', (err) => {
      logError('ENSURE_AUDIO_ERROR', 'FFmpeg spawn error', { error: err.message });
      reject(new Error(`FFmpeg error: ${err.message}`));
    });
  });
});

// Generate TTS audio using Google Cloud Text-to-Speech SDK
ipcMain.handle('generate-tts-direct', async (event, params) => {
  const { text, title, languageCode, voiceName, gender, speakingRate, pitch, savePath } = params;

  logInfo('TTS_SDK_START', 'Starting TTS generation with Google Cloud SDK', {
    textLength: text.length,
    languageCode,
    voiceName,
    gender,
    savePath
  });

  try {
    const textToSpeech = require('@google-cloud/text-to-speech');

    // Determine credentials path
    const serviceAccountPath = path.join(__dirname, 'google-tts-service-account.json');

    let client;

    // Try service account JSON file first
    if (fs.existsSync(serviceAccountPath)) {
      logInfo('TTS_SDK_AUTH', 'Using service account JSON file', {
        path: serviceAccountPath
      });

      client = new textToSpeech.TextToSpeechClient({
        keyFilename: serviceAccountPath
      });
    }
    // Fall back to API key if available
    else {
      const apiKey = process.env.GOOGLE_TTS_API_KEY || process.env.GOOGLE_AI_API_KEY;

      if (apiKey) {
        logInfo('TTS_SDK_AUTH', 'Using API key from environment variable');

        client = new textToSpeech.TextToSpeechClient({
          apiKey: apiKey
        });
      } else {
        logError('TTS_SDK_NO_AUTH', 'No authentication method found', {
          checkedFile: serviceAccountPath,
          checkedEnvVars: 'GOOGLE_TTS_API_KEY, GOOGLE_AI_API_KEY'
        });

        throw new Error(
          'Google TTS authentication not configured.\n\n' +
          'Please either:\n' +
          '1. Place google-tts-service-account.json in the app directory, or\n' +
          '2. Set GOOGLE_TTS_API_KEY or GOOGLE_AI_API_KEY environment variable'
        );
      }
    }

    // Construct the request
    const request = {
      input: { text: text },
      voice: {
        languageCode: languageCode,
        name: voiceName,
        ssmlGender: gender // MALE, FEMALE, NEUTRAL
      },
      audioConfig: {
        audioEncoding: 'MP3',
        speakingRate: speakingRate || 1.0,
        pitch: pitch || 0.0
      }
    };

    logInfo('TTS_SDK_REQUEST', 'Sending request to Google TTS API', {
      languageCode,
      voiceName,
      textLength: text.length
    });

    // Perform the Text-to-Speech request
    const [response] = await client.synthesizeSpeech(request);

    if (!response.audioContent) {
      logError('TTS_SDK_NO_AUDIO', 'No audio content in response');
      throw new Error('No audio content received from Google TTS API');
    }

    // Determine save path
    let audioPath;
    let filename;

    if (savePath) {
      // User specified save path (full generation)
      audioPath = savePath;
      filename = path.basename(audioPath);
    } else {
      // No save path specified (preview mode)
      const os = require('os');
      const tempDir = os.tmpdir();
      const timestamp = Date.now();
      filename = `tts_preview_${timestamp}.mp3`;
      audioPath = path.join(tempDir, filename);
    }

    // Write the binary audio content to a file
    fs.writeFileSync(audioPath, response.audioContent, 'binary');

    logInfo('TTS_SDK_SUCCESS', 'TTS audio generated and saved', {
      audioPath,
      fileSize: response.audioContent.length,
      isPreview: !savePath
    });

    return {
      success: true,
      audioPath,
      filename,
      fileSize: response.audioContent.length
    };

  } catch (error) {
    logError('TTS_SDK_ERROR', 'TTS generation failed', {
      error: error.message,
      stack: error.stack
    });

    throw new Error(`TTS generation failed: ${error.message}`);
  }
});

// ============================================================================
// Backend Authentication
// ============================================================================

/**
 * Login to backend server
 */
ipcMain.handle('backend-login', async (event, params) => {
  const { email, password, backendUrl } = params;

  logInfo('BACKEND_LOGIN', 'Attempting login', {
    email,
    backendUrl
  });

  try {
    const axios = require('axios');

    const response = await axios.post(
      `${backendUrl}/api/auth/login`,
      {
        email,
        password,
        appType: 'EDITOR'  // Identify this as editor app for separate token management
      },
      {
        headers: {
          'Content-Type': 'application/json'
        },
        timeout: 10000
      }
    );

    logInfo('BACKEND_LOGIN', 'Login successful', {
      email,
      hasToken: !!response.data?.token,
      hasRefreshToken: !!response.data?.refreshToken
    });

    return {
      success: true,
      token: response.data.token,
      refreshToken: response.data.refreshToken,
      user: {
        email: response.data.email || email,
        name: response.data.displayName || response.data.email || email,
        role: response.data.role
      }
    };

  } catch (error) {
    logError('BACKEND_LOGIN_ERROR', 'Login failed', {
      email,
      error: error.message,
      response: error.response?.data
    });

    if (error.response) {
      const status = error.response.status;
      const errorData = error.response.data;

      if (status === 401) {
        throw new Error('이메일 또는 비밀번호가 올바르지 않습니다.');
      } else if (status === 404) {
        throw new Error('백엔드 서버를 찾을 수 없습니다.\nURL을 확인해주세요.');
      } else {
        throw new Error(errorData?.message || `로그인 실패 (${status})`);
      }
    } else if (error.code === 'ECONNREFUSED') {
      throw new Error('백엔드 서버에 연결할 수 없습니다.\n서버가 실행 중인지 확인해주세요.');
    } else if (error.code === 'ETIMEDOUT' || error.code === 'ECONNABORTED') {
      throw new Error('서버 응답 시간이 초과되었습니다.\n네트워크 연결을 확인해주세요.');
    } else {
      throw new Error(`로그인 중 오류가 발생했습니다: ${error.message}`);
    }
  }
});

// ============================================================================
// File Download
// ============================================================================

/**
 * Download file from URL to temp directory
 */
ipcMain.handle('download-file', async (event, url, filename) => {
  logInfo('FILE_DOWNLOAD', 'Starting file download', {
    url: url.substring(0, 100),
    filename
  });

  try {
    const axios = require('axios');
    const path = require('path');
    const os = require('os');

    // Create temp directory path
    const tempDir = path.join(os.tmpdir(), 'video-editor-downloads');
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    // Generate unique filename to avoid conflicts
    const timestamp = Date.now();
    const ext = path.extname(filename) || '.tmp';
    const basename = path.basename(filename, ext);
    const uniqueFilename = `${basename}_${timestamp}${ext}`;
    const filePath = path.join(tempDir, uniqueFilename);

    logInfo('FILE_DOWNLOAD', 'Downloading to:', { filePath });

    // Check if this is a Google API URL and add API key if needed
    let downloadUrl = url;
    const headers = {};

    if (url.includes('generativelanguage.googleapis.com')) {
      const apiKey = process.env.GOOGLE_AI_API_KEY;
      if (apiKey) {
        // Add API key both as header and query parameter for maximum compatibility
        headers['x-goog-api-key'] = apiKey;

        // Also add as query parameter
        const separator = url.includes('?') ? '&' : '?';
        downloadUrl = `${url}${separator}key=${apiKey}`;

        logInfo('FILE_DOWNLOAD', 'Adding Google API key to request (header + query param)');
      } else {
        logError('FILE_DOWNLOAD', 'Google API URL but no API key found');
        throw new Error('GOOGLE_AI_API_KEY environment variable not set');
      }
    }

    // Download file
    const response = await axios({
      method: 'GET',
      url: downloadUrl,
      responseType: 'stream',
      timeout: 300000, // 5 minutes timeout
      headers: headers
    });

    // Write to file
    const writer = fs.createWriteStream(filePath);
    response.data.pipe(writer);

    // Wait for download to complete
    await new Promise((resolve, reject) => {
      writer.on('finish', resolve);
      writer.on('error', reject);
    });

    logInfo('FILE_DOWNLOAD', 'Download complete', {
      filePath,
      size: fs.statSync(filePath).size
    });

    return {
      success: true,
      filePath: filePath,
      filename: uniqueFilename
    };

  } catch (error) {
    logError('FILE_DOWNLOAD_ERROR', 'Download failed', {
      url: url.substring(0, 100),
      filename,
      error: error.message
    });

    return {
      success: false,
      error: error.message
    };
  }
});

// ============================================================================
// Runway ML API Integration (Image Generation)
// ============================================================================

/**
 * Generate image using Runway ML API
 */
ipcMain.handle('generate-image-runway', async (event, params) => {
  const { imagePaths, prompt, style, aspectRatio } = params;

  logInfo('RUNWAY_IMAGE', 'Starting Runway ML image generation', {
    imageCount: imagePaths?.length || 0,
    prompt: prompt?.substring(0, 50),
    style,
    aspectRatio
  });

  try {
    // Get Runway API key from environment variable
    const RUNWAY_API_KEY = process.env.RUNWAY_API_KEY;

    if (!RUNWAY_API_KEY) {
      throw new Error('RUNWAY_API_KEY 환경변수가 설정되지 않았습니다.\n\n환경변수를 설정하거나 .env 파일을 생성하세요.');
    }

    // Validate inputs
    if (!imagePaths || imagePaths.length === 0) {
      throw new Error('참조 이미지를 최소 1개 이상 선택해주세요.');
    }

    if (!prompt || prompt.trim() === '') {
      throw new Error('프롬프트를 입력해주세요.');
    }

    // Parse target aspect ratio
    const [targetWidth, targetHeight] = (aspectRatio || '1024:1024').split(':').map(Number);
    const targetRatio = targetWidth / targetHeight;

    logInfo('RUNWAY_IMAGE', 'Target aspect ratio', {
      ratio: aspectRatio,
      targetWidth,
      targetHeight,
      targetRatio: targetRatio.toFixed(2)
    });

    // Convert image files to base64 with aspect ratio adjustment
    const sharp = require('sharp');
    const imageDataArray = [];

    for (const imagePath of imagePaths) {
      if (imagePath && fs.existsSync(imagePath)) {
        // Load image and get metadata
        const imageBuffer = fs.readFileSync(imagePath);
        const metadata = await sharp(imageBuffer).metadata();

        logInfo('RUNWAY_IMAGE', `Original image ${imageDataArray.length + 1}`, {
          width: metadata.width,
          height: metadata.height,
          ratio: (metadata.width / metadata.height).toFixed(2)
        });

        // Resize/crop image to match target aspect ratio
        // Use cover strategy to fill the entire target dimensions
        const processedBuffer = await sharp(imageBuffer)
          .resize(targetWidth, targetHeight, {
            fit: 'cover',  // Crop to fill the dimensions
            position: 'center'  // Center crop
          })
          .jpeg({ quality: 90 })  // Convert to JPEG for smaller size
          .toBuffer();

        const base64Data = processedBuffer.toString('base64');
        imageDataArray.push({
          uri: `data:image/jpeg;base64,${base64Data}`,
          tag: `reference_${imageDataArray.length + 1}`
        });

        logInfo('RUNWAY_IMAGE', `Processed reference image ${imageDataArray.length}`, {
          path: imagePath,
          originalSize: imageBuffer.length,
          processedSize: processedBuffer.length,
          dimensions: `${targetWidth}x${targetHeight}`
        });
      }
    }

    if (imageDataArray.length === 0) {
      throw new Error('유효한 참조 이미지를 찾을 수 없습니다.');
    }

    // Runway API supports maximum 3 reference images
    if (imageDataArray.length > 3) {
      logInfo('RUNWAY_IMAGE', `Warning: ${imageDataArray.length} images provided, but Runway API only supports 3. Using first 3 images.`);
      imageDataArray.splice(3); // Keep only first 3
    }

    // Add style to prompt
    let enhancedPrompt = prompt;
    if (style && style !== 'realistic') {
      enhancedPrompt = `${prompt}, ${style} style`;
    }

    // Prepare API request payload
    const requestBody = {
      model: 'gen4_image',
      promptText: enhancedPrompt,
      referenceImages: imageDataArray,
      ratio: aspectRatio || '1024:1024'
    };

    logInfo('RUNWAY_IMAGE', 'Calling Runway ML API', {
      url: 'https://api.dev.runwayml.com/v1/text_to_image',
      promptLength: enhancedPrompt.length,
      imageCount: imageDataArray.length
    });

    // Call Runway ML API
    const https = require('https');
    const axios = require('axios');

    const response = await axios.post(
      'https://api.dev.runwayml.com/v1/text_to_image',
      requestBody,
      {
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${RUNWAY_API_KEY}`,
          'X-Runway-Version': '2024-11-06'
        },
        timeout: 120000, // 2 minutes
        httpsAgent: new https.Agent({
          rejectUnauthorized: false
        })
      }
    );

    logInfo('RUNWAY_IMAGE', 'Runway ML API response received', {
      status: response.status,
      hasTaskId: !!response.data?.id
    });

    if (!response.data || !response.data.id) {
      throw new Error('Runway ML API에서 작업 ID를 받지 못했습니다.');
    }

    const taskId = response.data.id;

    return {
      success: true,
      taskId: taskId,
      message: '이미지 생성 작업이 시작되었습니다.'
    };

  } catch (error) {
    logError('RUNWAY_IMAGE_ERROR', 'Runway image generation failed', {
      error: error.message,
      response: error.response?.data,
      status: error.response?.status
    });

    // Handle specific error codes
    if (error.response) {
      const status = error.response.status;
      const errorData = error.response.data;

      if (status === 401) {
        throw new Error('Runway ML API 인증 실패\n\nAPI 키가 올바르지 않거나 만료되었습니다.');
      } else if (status === 402) {
        throw new Error('Runway ML 크레딧 부족\n\n계정 크레딧을 충전해주세요.');
      } else if (status === 429) {
        throw new Error('API 요청 한도 초과\n\n잠시 후 다시 시도해주세요.');
      } else {
        throw new Error(`Runway ML API 오류 (${status}): ${errorData?.message || error.message}`);
      }
    }

    throw error;
  }
});

/**
 * Generate video with Runway ML (Image to Video)
 */
ipcMain.handle('generate-video-runway', async (event, params) => {
  logInfo('RUNWAY_VIDEO', 'Starting Runway video generation', {
    model: params.model,
    duration: params.duration,
    hasImage1: !!params.image1Path,
    hasImage2: !!params.image2Path
  });

  try {
    const RUNWAY_API_KEY = process.env.RUNWAY_API_KEY;

    if (!RUNWAY_API_KEY) {
      throw new Error('RUNWAY_API_KEY 환경변수가 설정되지 않았습니다.\n\n환경변수를 설정하거나 .env 파일을 생성하세요.');
    }

    const https = require('https');
    const axios = require('axios');

    // Read and convert images to base64
    const convertImageToBase64 = async (imagePath) => {
      if (!imagePath) return null;

      // Check if it's a URL (S3 presigned URL)
      if (imagePath.startsWith('http://') || imagePath.startsWith('https://')) {
        // For S3 URLs, fetch the image and convert to base64
        const imageResponse = await axios.get(imagePath, { responseType: 'arraybuffer' });
        const base64 = Buffer.from(imageResponse.data).toString('base64');
        return `data:image/jpeg;base64,${base64}`;
      } else {
        // For local files
        const imageBuffer = fs.readFileSync(imagePath);
        const base64 = imageBuffer.toString('base64');
        return `data:image/jpeg;base64,${base64}`;
      }
    };

    const image1Base64 = await convertImageToBase64(params.image1Path);
    const image2Base64 = params.image2Path ? await convertImageToBase64(params.image2Path) : null;

    // Map resolution to Runway API ratio format
    let ratio = '1280:720'; // Default 720p landscape
    if (params.resolution === '1080p') {
      ratio = '1920:1080';
    } else if (params.resolution === '720p') {
      ratio = '1280:720';
    }

    // Prepare request body for Runway image_to_video API
    const requestBody = {
      model: params.model || 'gen3a_turbo',
      promptText: params.prompt,
      duration: parseInt(params.duration) || 5,
      ratio: ratio
    };

    // Add promptImage (required field for image-to-video)
    if (image1Base64) {
      requestBody.promptImage = image1Base64;
    }

    // If second image is provided, add it (check if API supports this)
    if (image2Base64) {
      // Note: Runway may not support interpolation in gen3, but keep for future
      requestBody.lastFrameImage = image2Base64;
    }

    logInfo('RUNWAY_VIDEO', 'Calling Runway ML API', {
      url: 'https://api.dev.runwayml.com/v1/image_to_video',
      model: requestBody.model,
      duration: requestBody.duration,
      ratio: requestBody.ratio,
      hasPromptImage: !!requestBody.promptImage,
      hasLastFrameImage: !!requestBody.lastFrameImage
    });

    // Call Runway ML API
    const response = await axios.post(
      'https://api.dev.runwayml.com/v1/image_to_video',
      requestBody,
      {
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${RUNWAY_API_KEY}`,
          'X-Runway-Version': '2024-11-06'
        },
        timeout: 60000,
        httpsAgent: new https.Agent({
          rejectUnauthorized: false
        })
      }
    );

    // Log full response for debugging
    logInfo('RUNWAY_VIDEO', 'API response received', {
      responseData: JSON.stringify(response.data)
    });

    // Extract task ID - Runway API may use different field names
    const taskId = response.data.id || response.data.taskId || response.data.task_id;

    if (!taskId) {
      logError('RUNWAY_VIDEO_ERROR', 'No task ID in response', {
        responseData: response.data
      });
      throw new Error('API 응답에서 작업 ID를 찾을 수 없습니다.');
    }

    logInfo('RUNWAY_VIDEO', 'Task created successfully', {
      taskId,
      status: response.data.status
    });

    return {
      success: true,
      taskId: taskId,
      status: response.data.status
    };

  } catch (error) {
    logError('RUNWAY_VIDEO_ERROR', 'Failed to generate video', {
      error: error.message,
      response: error.response?.data
    });

    return {
      success: false,
      error: error.message,
      details: error.response?.data
    };
  }
});

/**
 * Download Runway ML generated video
 */
ipcMain.handle('download-runway-video', async (event, videoUrl) => {
  logInfo('RUNWAY_DOWNLOAD', 'Downloading generated video', { videoUrl });

  try {
    const axios = require('axios');
    const path = require('path');
    const os = require('os');

    // Create temp directory if it doesn't exist
    const tempDir = path.join(os.tmpdir(), 'kiosk-video-editor');
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    // Generate unique filename
    const timestamp = Date.now();
    const filename = `runway_video_${timestamp}.mp4`;
    const filePath = path.join(tempDir, filename);

    // Download video
    const response = await axios({
      method: 'GET',
      url: videoUrl,
      responseType: 'stream',
      timeout: 120000 // 2 minutes
    });

    // Save to file
    const writer = fs.createWriteStream(filePath);
    response.data.pipe(writer);

    await new Promise((resolve, reject) => {
      writer.on('finish', resolve);
      writer.on('error', reject);
    });

    logInfo('RUNWAY_DOWNLOAD', 'Video downloaded successfully', {
      filePath,
      size: fs.statSync(filePath).size
    });

    return {
      success: true,
      filePath: filePath
    };

  } catch (error) {
    logError('RUNWAY_DOWNLOAD_ERROR', 'Failed to download video', {
      error: error.message
    });

    return {
      success: false,
      error: error.message
    };
  }
});

/**
 * Poll Runway ML task status
 */
ipcMain.handle('poll-runway-task', async (event, taskId) => {
  logInfo('RUNWAY_POLL', 'Polling Runway ML task status', { taskId });

  try {
    const RUNWAY_API_KEY = process.env.RUNWAY_API_KEY;

    if (!RUNWAY_API_KEY) {
      throw new Error('RUNWAY_API_KEY not configured');
    }

    const https = require('https');
    const axios = require('axios');

    const response = await axios.get(
      `https://api.dev.runwayml.com/v1/tasks/${taskId}`,
      {
        headers: {
          'Authorization': `Bearer ${RUNWAY_API_KEY}`,
          'X-Runway-Version': '2024-11-06'
        },
        timeout: 30000,
        httpsAgent: new https.Agent({
          rejectUnauthorized: false
        })
      }
    );

    const taskData = response.data;
    const status = taskData.status;

    logInfo('RUNWAY_POLL', 'Task status received', {
      taskId,
      status,
      hasOutput: !!taskData.output
    });

    return {
      status: status,
      output: taskData.output,
      failure: taskData.failure,
      failureCode: taskData.failureCode
    };

  } catch (error) {
    logError('RUNWAY_POLL_ERROR', 'Failed to poll task status', {
      taskId,
      error: error.message
    });
    throw error;
  }
});

/**
 * Generate video with Google VEO API using Gemini API (matching backend implementation)
 */
ipcMain.handle('generate-veo-video', async (event, params) => {
  return await veoHelper.generateVeoVideo(params, logInfo, logError);
});

logInfo('SYSTEM', 'Kiosk Video Editor initialized');
/**
 * Generate image with Google Imagen
 */
ipcMain.handle('generate-imagen-image', async (event, params) => {
  return await imagenHelper.generateImagenImage(params, logInfo, logError);
});

/**
 * Read audio file and return as Base64 for blob URL creation
 */
ipcMain.handle('read-audio-file', async (event, filePath) => {
  try {
    // Check if file exists first
    if (!fs.existsSync(filePath)) {
      logError('FILE', `Audio file not found: ${filePath}`);
      return {
        success: false,
        error: `File not found: ${filePath}`
      };
    }

    // Get file stats
    const stats = fs.statSync(filePath);
    logInfo('FILE', `Reading audio file: ${filePath} (${stats.size} bytes)`);

    // Read file
    const buffer = await fs.promises.readFile(filePath);
    const base64 = buffer.toString('base64');

    logInfo('FILE', `Audio file read successfully: ${base64.length} characters in base64`);

    return {
      success: true,
      base64: base64,
      mimeType: 'audio/mpeg', // MP3 format from TTS
      fileSize: stats.size
    };
  } catch (error) {
    logError('FILE', `Failed to read audio file: ${error.message}`, {
      filePath,
      error: error.stack
    });
    return {
      success: false,
      error: `Failed to read audio file: ${error.message}`
    };
  }
});
